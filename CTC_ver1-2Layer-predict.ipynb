{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTC version 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Paper Reference\n",
    "- [Connectionist Temporal Classification (IDSIA)](ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf)\n",
    "\n",
    "\n",
    "### English Test\n",
    "First we test English\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Include And \n",
    "import sys\n",
    "sys.path.append(\"/home/pika/nntools/\")\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from theano_toolkit import utils as U\n",
    "from theano_toolkit import updates\n",
    "from theano.printing import Print\n",
    "from theano_toolkit.parameters import Parameters\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "from time import time\n",
    "\n",
    "import ctc_cost_2\n",
    "\n",
    "import cPickle\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concate\n",
      "Dataset Finish : \n",
      "total x_test = 4157\n",
      "[[ 0.          0.          0.         ...,  0.80623442  0.87935519\n",
      "   2.1857326 ]\n",
      " [ 0.          0.          0.         ...,  0.55712402  1.00187135\n",
      "   1.96597409]\n",
      " [ 0.          0.          0.         ...,  0.39103299  0.83919752\n",
      "   2.55425239]\n",
      " ..., \n",
      " [ 0.83257371  0.8675769   0.23479289 ...,  0.          0.          0.        ]\n",
      " [ 0.9678601   0.89204186  0.23479289 ...,  0.          0.          0.        ]\n",
      " [ 1.19436431  0.95320964  0.19766235 ...,  0.          0.          0.        ]]\n",
      "total y_test = 4157\n",
      "[ 24.  19.  12.  28.   5.   1.   0.  14.  24.  16.  24.  22.  25.   5.   0.\n",
      "  16.   5.  19.   0.  12.  16.  18.   0.  19.  10.   5.   0.   8.  29.   5.\n",
      "  16.   0.  10.   5.  19.  12.  19.   5.   0.  15.  24.  19.   0.  21.   5.\n",
      "  22.   5.  23.   0.  14.   5.   9.  25.  18.   0.  15.  24.  19.]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Doing : \n",
    "    - Read data and return x_test, y_test\n",
    "'''\n",
    "# TRAINING_ACOUSTIC_FEATURE = \"./dataCebuano/train.f0_ffv_fbank.fea\"\n",
    "# TRAINING_ACOUSTIC_FEATURE = \"./dataCebuano/train_Normalized_SELFVALID.ark\"\n",
    "# TRAINING_ACOUSTIC_FEATURE = \"./dataCebuano/train_Normalized_SELFVALID_LenLessThen500.ark\"\n",
    "# TRAINING_LABELS = \"./dataCebuano/train.txt\"\n",
    "\n",
    "# TESTING_ACOUSTIC_FEATURE = './dataCebuano/dev_Normalized_SELFVALID_originLength.ark'\n",
    "TESTING_ACOUSTIC_FEATURE = './dataCebuano/dev_Normalized_SELFVALID_LenLessThen500.ark'\n",
    "TESTING_LABELS = './dataCebuano/dev.txt'\n",
    "\n",
    "\n",
    "CHAR_CORPUS = \"./dataCebuano/corpus.txt\"\n",
    "\n",
    "\n",
    "def readDataSet () :\n",
    "    \n",
    "    # -- Mapping char to integer and reverse\n",
    "    char_map = {}    # eg. { a -> 1 }\n",
    "    char_unMap = {}  # eg. { 1 -> a }\n",
    "    with open( CHAR_CORPUS, 'r' ) as f:\n",
    "        char_index = 0\n",
    "        for lines in f:\n",
    "            char_map  [ lines[:-1] ] = char_index\n",
    "            char_unMap[ char_index ] = lines[:-1]\n",
    "            char_index += 1\n",
    "        # add Blank, take '.' as blank (not space)\n",
    "        char_map['.'] = char_index\n",
    "        char_unMap[char_index] = '.'\n",
    "    \n",
    "    \n",
    "    # -- Reading X = id -> [ list of feature ] \n",
    "    idMapX = {}\n",
    "    idDeck = []\n",
    "    id = ''\n",
    "    \n",
    "    tmp_l = 0;\n",
    "    with open( TESTING_ACOUSTIC_FEATURE, 'r') as f:\n",
    "        for lines in f: \n",
    "            if '[' in lines :\n",
    "                id = lines.split(' ')[0]\n",
    "                idDeck.append(id)\n",
    "                idMapX[id] = []\n",
    "            elif ']' in lines :\n",
    "                if( len( lines.split('\\n')[0].split(' ') [0:-1] ) != 33 ) :\n",
    "                    print \"err\"\n",
    "                    return \n",
    "                idMapX[id].append([float(x) for x in lines.split('\\n')[0].split(' ') [:-1] ])\n",
    "            else :\n",
    "                if( len( lines.split('\\n')[0].split(' ')) != 33 ):\n",
    "                    print len( lines.split('\\n')[0].split(' '))\n",
    "                    print lines.split('\\n')[0].split(' ')\n",
    "                    print lines\n",
    "                    print id\n",
    "                    print \"fuck\"\n",
    "                    return\n",
    "                idMapX[id].append([float(x) for x in lines.split('\\n')[0].split(' ') ])\n",
    "    \n",
    "    # Move to  3 - main - 3\n",
    "    \n",
    "    monoDimension = 33;\n",
    "    zeroFeature = [0] * monoDimension\n",
    "    #print len( zeroFeature ) \n",
    "    #print zeroFeature\n",
    "    for id in idDeck:\n",
    "        # print id\n",
    "        tmpIdMapXWithID = []\n",
    "        if len(idMapX[id]) < 6 :\n",
    "            print \"ERROR in length\"\n",
    "            return \n",
    "        for idxX in xrange( len(idMapX[id]) ):\n",
    "            if idxX == 0:\n",
    "                tmpIdMapXWithID.append( zeroFeature + zeroFeature + zeroFeature + idMapX[id][idxX] + idMapX[id][idxX+1] + idMapX[id][idxX+2] + idMapX[id][idxX+3] )    \n",
    "            elif idxX == 1:\n",
    "                tmpIdMapXWithID.append( zeroFeature + zeroFeature + idMapX[id][idxX-1] + idMapX[id][idxX] + idMapX[id][idxX+1] + idMapX[id][idxX+2] + idMapX[id][idxX+3] )  \n",
    "            elif idxX == 2:\n",
    "                tmpIdMapXWithID.append( zeroFeature + idMapX[id][idxX-2] + idMapX[id][idxX-1] + idMapX[id][idxX] + idMapX[id][idxX+1] + idMapX[id][idxX+2] + idMapX[id][idxX+3] )  \n",
    "            elif idxX == (len(idMapX[id]) - 3 ):\n",
    "                tmpIdMapXWithID.append( idMapX[id][idxX-3] + idMapX[id][idxX-2] + idMapX[id][idxX-1] + idMapX[id][idxX] + idMapX[id][idxX+1] + idMapX[id][idxX+2] + zeroFeature )  \n",
    "            elif idxX == (len(idMapX[id]) - 2 ):\n",
    "                tmpIdMapXWithID.append( idMapX[id][idxX-3] + idMapX[id][idxX-2] + idMapX[id][idxX-1] + idMapX[id][idxX] + idMapX[id][idxX+1] + zeroFeature + zeroFeature )  \n",
    "            elif idxX == (len(idMapX[id]) - 1 ):\n",
    "                tmpIdMapXWithID.append( idMapX[id][idxX-3] + idMapX[id][idxX-2] + idMapX[id][idxX-1] + idMapX[id][idxX] + zeroFeature + zeroFeature + zeroFeature )  \n",
    "            else:\n",
    "                tmpIdMapXWithID.append( idMapX[id][idxX-3] + idMapX[id][idxX-2] + idMapX[id][idxX-1] + idMapX[id][idxX] + idMapX[id][idxX+1] + idMapX[id][idxX+2] + idMapX[id][idxX+3] )  \n",
    "        idMapX[id] = tmpIdMapXWithID\n",
    "    \n",
    "    print \"Concate\"\n",
    "    \n",
    "    # Standardlize X (Done in PrepreProcessing )\n",
    "   \n",
    "    id_test = idDeck\n",
    "    \n",
    "    idMapY = {} \n",
    "    \n",
    "    checkPara = 0\n",
    "    # -- Reading Y = id -> [ Sentence(list of char[int] ) ]\n",
    "    with open( TESTING_LABELS, 'r') as f:\n",
    "        specific = '?'\n",
    "        for lines in f:\n",
    "            yWithId = lines.split('\\n')[0].split(' ', 1)\n",
    "            idMapY[ yWithId[0] ] = []\n",
    "            judgeSpecific = False\n",
    "            for char in yWithId[1] :\n",
    "                if char == '(' and checkPara == 0 : \n",
    "                    checkPara = 3\n",
    "                elif checkPara > 0 :\n",
    "                    checkPara -= 1\n",
    "                    if checkPara == 0 :\n",
    "                        idMapY[ yWithId[0] ].append( char_map[specific] )\n",
    "                else :\n",
    "                    if char == '<' :\n",
    "                        judgeSpecific = True;                \n",
    "                    if( judgeSpecific ):\n",
    "                        if char == '>':\n",
    "                            idMapY[ yWithId[0] ].append( char_map[specific] )\n",
    "                            judgeSpecific = False\n",
    "                    else :\n",
    "                        idMapY[ yWithId[0] ].append( char_map[char.lower()] )\n",
    "    \n",
    "    # -- concatenate X and Y\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    idCollect = []\n",
    "    for id in id_test:\n",
    "        concateId = []\n",
    "        for i in range( len( idMapX[id] ) ) :\n",
    "            concateId.append( idMapX[id][i] )\n",
    "        x_test.append( floatX( concateId )  )\n",
    "        y_test.append( floatX( idMapY[id]) )\n",
    "        idCollect.append( id )\n",
    "    \n",
    "    print \"Dataset Finish : \"\n",
    "    print \"total x_test = \" + str(len(x_test))\n",
    "    print x_test[0]\n",
    "    print \"total y_test = \" + str(len(y_test))\n",
    "    print y_test[0]\n",
    "    \n",
    "    return char_map, char_unMap, x_test, y_test, idCollect\n",
    "\n",
    "def floatX(x):\n",
    "    return np.asarray(x, dtype=theano.config.floatX)\n",
    "\n",
    "# Original 4381\n",
    "# lessthen500 4157\n",
    "\n",
    "char_map, char_unMap, x_test, y_test, idCollect = readDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 231)\n",
      "(58,)\n"
     ]
    }
   ],
   "source": [
    "# 500 -> 3722 / 195\n",
    "# 600 -> 3821 / 201\n",
    "# 3000 -> 3937 / 207\n",
    "print x_test[0].shape\n",
    "print y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "print max( [X.shape[0] for X in x_test] )\n",
    "print max( [Y.shape[0] for Y in y_test] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def make_batches_X(XLen, X, length, batch_size=30):\n",
    "    n_batches = int(round(XLen*1./batch_size))\n",
    "    X_batch = np.zeros( (n_batches, batch_size, length, X[0].shape[1]),\n",
    "                       dtype=theano.config.floatX)\n",
    "    X_mask  = np.zeros( (n_batches, length, batch_size ), \n",
    "                       dtype=theano.config.floatX)\n",
    "\n",
    "    count = 0\n",
    "    for b in range(n_batches): \n",
    "        for n in range(batch_size): # go thorough batch size\n",
    "            \n",
    "            if ( XLen > (b*batch_size + n )):\n",
    "                count += 1\n",
    "                \n",
    "                X_m = X[b*batch_size + n] # seq_length X feature dim\n",
    "                X_batch[b, n, :X_m.shape[0]] = X_m[:length]\n",
    "                X_mask[b, :X_m.shape[0], n] = 1\n",
    "    print count\n",
    "            \n",
    "    return X_batch, X_mask\n",
    "\n",
    "'''\n",
    "\n",
    "def make_batches_X(X, length, batch_size=30):\n",
    "    n_batches = len(X)//batch_size\n",
    "    X_batch = np.zeros( (n_batches, batch_size, length, X[0].shape[1]),\n",
    "                         dtype=theano.config.floatX)\n",
    "    X_mask  = np.zeros( (n_batches, length, batch_size ), \n",
    "                         dtype=theano.config.floatX)\n",
    "    \n",
    "    for b in range(n_batches): \n",
    "        for n in range(batch_size): # go thorough batch size       \n",
    "            X_m = X[b*batch_size + n] # seq_length X feature dim            \n",
    "            X_batch[b, n, :X_m.shape[0]] = X_m[:length]\n",
    "            X_mask[b, :X_m.shape[0], n] = 1\n",
    "            \n",
    "    return X_batch, X_mask\n",
    "\n",
    "def make_batches_Y( X, length, batch_size=30):\n",
    "    n_batches = len(X)//batch_size\n",
    "    \n",
    "    X_batch = np.zeros( (n_batches, length, batch_size ), dtype='float32')\n",
    "    \n",
    "    X_mask = np.zeros(X_batch.shape, dtype=theano.config.floatX)\n",
    "    \n",
    "    for b in range(n_batches):\n",
    "        for n in range(batch_size):\n",
    "            X_m = X[ b*batch_size + n ]\n",
    "            X_batch[b, :X_m.shape[0], n ] = X_m[:length]\n",
    "            X_mask[b, :X_m.shape[0], n] = 1\n",
    "    return X_batch, X_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "batch_size = 12\n",
    "\n",
    "# Find the longest sequence\n",
    "# length_x = max( [X.shape[0] for X in x_test] )\n",
    "\n",
    "# length_x = 1670\n",
    "length_y = 206\n",
    "\n",
    "# Convert to batches of time series of uniform length\n",
    "# x_test_mask: seq_length X batch_size\n",
    "# y_test_mask: output_length X batch_size\n",
    "# y_pred_mask = x_test_mask, since pred by sequence\n",
    "\n",
    "\n",
    "# x_test, x_test_mask = make_batches_X(len(x_test), x_test, length_x, batch_size)\n",
    "y_test, y_test_mask = make_batches_X(len(y_test), y_test, length_y, batch_size)\n",
    "'''\n",
    "\n",
    "batch_size = 40\n",
    "# batch_size = 12\n",
    "\n",
    "# Find the longest sequence\n",
    "length_x = max( [X.shape[0] for X in x_test] )\n",
    "length_y = max( [X.shape[0] for X in y_test] )\n",
    "\n",
    "# Convert to batches of time series of uniform length\n",
    "# x_train_mask: seq_length X batch_size\n",
    "# y_train_mask: output_length X batch_size\n",
    "# y_pred_mask = x_train_mask, since pred by sequence\n",
    "x_test, x_test_mask = make_batches_X(x_test, length_x, batch_size)\n",
    "y_test, y_test_mask = make_batches_Y(y_test, length_y, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 40, 501, 231)\n",
      "(103, 127, 40)\n",
      "===============mask================\n",
      "(103, 501, 40)\n",
      "(103, 127, 40)\n"
     ]
    }
   ],
   "source": [
    "print x_test.shape\n",
    "print y_test.shape\n",
    "print \"===============mask================\"\n",
    "print x_test_mask.shape\n",
    "print y_test_mask.shape\n",
    "\n",
    "# print x_test_mask[0][400][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _count_grade( r, h):\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitution = d[i-1][j-1] + 1\n",
    "                insertion    = d[i][j-1] + 1\n",
    "                deletion     = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    point = float(d[len(r)][len(h)])/float(len(r))\n",
    "    # print point \n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print _count_grade( \"hello\", \"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "credit by NLTK package of measure edit distance\n",
    "'''\n",
    "\n",
    "def _edit_dist_init(len1, len2):\n",
    "    lev = []\n",
    "    for i in range(len1):\n",
    "        lev.append([0] * len2)  # initialize 2D array to zero\n",
    "    for i in range(len1):\n",
    "        lev[i][0] = i           # column 0: 0,1,2,3,4,...\n",
    "    for j in range(len2):\n",
    "        lev[0][j] = j           # row 0: 0,1,2,3,4,...\n",
    "    return lev\n",
    "\n",
    "\n",
    "def _edit_dist_step(lev, i, j, s1, s2, transpositions=False):\n",
    "    c1 = s1[i - 1]\n",
    "    c2 = s2[j - 1]\n",
    "\n",
    "    # skipping a character in s1\n",
    "    a = lev[i - 1][j] + 1\n",
    "    # skipping a character in s2\n",
    "    b = lev[i][j - 1] + 1\n",
    "    # substitution\n",
    "    c = lev[i - 1][j - 1] + (c1 != c2)\n",
    "\n",
    "    # transposition\n",
    "    d = c + 1  # never picked by default\n",
    "    if transpositions and i > 1 and j > 1:\n",
    "        if s1[i - 2] == c2 and s2[j - 2] == c1:\n",
    "            d = lev[i - 2][j - 2] + 1\n",
    "\n",
    "    # pick the cheapest\n",
    "    lev[i][j] = min(a, b, c, d)\n",
    "\n",
    "\n",
    "def check_label_error( real , predict, transpositions=False):\n",
    "    ## length of real >= length of predict\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein edit-distance between two strings.\n",
    "    The edit distance is the number of characters that need to be\n",
    "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
    "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
    "    consisting of two substitutions and one insertion:\n",
    "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
    "    been done in other orders, but at least three steps are needed.\n",
    "\n",
    "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
    "    though this is disabled by default.\n",
    "\n",
    "    :param s1, s2: The strings to be analysed\n",
    "    :param transpositions: Whether to allow transposition edits\n",
    "    :type s1: str\n",
    "    :type s2: str\n",
    "    :type transpositions: bool\n",
    "    :rtype int\n",
    "    \"\"\"\n",
    "    # set up a 2-D array\n",
    "    len1 = len(predict)\n",
    "    len2 = len(real)\n",
    "    lev = _edit_dist_init(len1 + 1, len2 + 1)\n",
    "\n",
    "    # iterate over the array\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            _edit_dist_step(lev, i + 1, j + 1, predict, real, transpositions=transpositions)\n",
    "            \n",
    "    return lev[len1][len2]*1.0/len2\n",
    "\n",
    "\n",
    "def clean_up( y ):\n",
    "    \"\"\"\n",
    "    for final output clean up\n",
    "    B(a − ab−) = B(−aa − −abb) = aab\n",
    "    \"\"\"\n",
    "    answer = \"\"\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == '.':\n",
    "            continue\n",
    "        else:\n",
    "            if y[i-1] != y[i]:\n",
    "                answer += y[i]\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def remap_back( y , actual):\n",
    "    answer = \"\"\n",
    "    \n",
    "    for i in y:\n",
    "        answer += char_unMap[i]\n",
    "    \n",
    "    if not actual:\n",
    "        answer = clean_up(answer)\n",
    "        \n",
    "    return answer\n",
    "\n",
    "def decode_all_actual( y, y_mask ,batch_size , actual=False):\n",
    "    \"\"\"\n",
    "    y     : label_length X batch_size\n",
    "    y_mask: label_length X batch_size\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in xrange(batch_size):\n",
    "        mask = np.swapaxes( y_mask, 0, 1)[i]\n",
    "        ans = np.swapaxes( y, 0 , 1)[i]\n",
    "        result.append(remap_back( ans[np.nonzero(mask)] , actual ))\n",
    "    return result\n",
    "\n",
    "\n",
    "def decode_all_pred( y, y_mask ,batch_size , actual=False):\n",
    "    \"\"\"\n",
    "    y     : label_length X batch_size\n",
    "    y_mask: label_length X batch_size\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in xrange(batch_size):\n",
    "        mask = np.swapaxes( y_mask, 0, 1)[i]\n",
    "        ans = y[i]\n",
    "        result.append(remap_back( ans[np.nonzero(mask)] , actual ))\n",
    "    return result\n",
    "\n",
    "def check_all( y, y_mask, y_pred, y_pred_mask, batch_size ):\n",
    "    \n",
    "    actual = decode_all_actual( y, y_mask, batch_size , True )\n",
    "    predict = decode_all_pred( y_pred, y_pred_mask, batch_size , False )\n",
    "    \n",
    "    error = 0.\n",
    "    for a,b in zip (actual, predict):\n",
    "        error += check_label_error(a,b)\n",
    "    \n",
    "    return error/len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class end_to_end():  \n",
    "    def __init__(self, input_shape, max_seq_length, hidden_layer,\n",
    "                 batch, max_epochs, output_num_units,\n",
    "                 patience, up_learning_rate, file_name):\n",
    "        \n",
    "        self.input_shape = input_shape # [batch, dim]\n",
    "        \n",
    "        self.hidden_layer = hidden_layer # hidden [l1, l2, l3]\n",
    "        self.output_num_units = output_num_units # [ # of class ]\n",
    "        \n",
    "        self.batch = batch\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.up_learning_rate = up_learning_rate\n",
    "                 \n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_params = None\n",
    "        \n",
    "        self.train_history_ = []\n",
    "        self.epochs = 0\n",
    "        \n",
    "        self.file_name = file_name\n",
    "        \n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        \"\"\"\n",
    "        input data type\n",
    "        y_hat : T x B x C+1\n",
    "        y : L x B\n",
    "        y_hat_mask : T x B\n",
    "        y_mask : L x B\n",
    "        \"\"\"\n",
    "        \n",
    "        print \"Why model build so long ... \"\n",
    "        # T x B x F\n",
    "        # B X T X F (Lasagne format)\n",
    "        x = T.tensor3('X', dtype=theano.config.floatX)\n",
    "        # L x B\n",
    "        y = T.matrix ('y', dtype=theano.config.floatX)\n",
    "\n",
    "        # L x B\n",
    "        y_mask = T.matrix('y_mask', dtype=theano.config.floatX)\n",
    "        # T x B\n",
    "        y_hat_mask = T.matrix('y_hat_mask', dtype=theano.config.floatX)\n",
    "    \n",
    "        # Min/max sequence length\n",
    "        MAX_LENGTH = max_seq_length\n",
    "        \n",
    "        # Number of training sequences in each batch\n",
    "        N_BATCH = batch\n",
    "        \n",
    "        #===========================================================================================\n",
    "        # dEEP lSTM\n",
    "        #===========================================================================================\n",
    "        print \"Input : (N_BATCH) : \" + str(N_BATCH) +\", ML :\" + str(MAX_LENGTH) + \"ss :\" + str(self.input_shape[1])\n",
    "        \n",
    "        # Recurrent layers expect input of shape\n",
    "        # (batch size, max sequence length, number of features)\n",
    "        l_in     = lasagne.layers.InputLayer( shape=( N_BATCH, MAX_LENGTH, self.input_shape[1] ) )\n",
    "        # l_in_gau = lasagne.layers.GaussianNoiseLayer( l_in, sigma=0.5 )\n",
    "        \n",
    "        # LSTM layer 1\n",
    "        l_forward_1   = lasagne.layers.LSTMLayer(l_in, num_units=hidden_layer[0], learn_init=True, peepholes=True)\n",
    "        l_backward_1  = lasagne.layers.LSTMLayer(l_in, num_units=hidden_layer[0], backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_1 = ElemwiseSumLayer( [l_forward_1, l_backward_1] )\n",
    "\n",
    "        \n",
    "        # LSTM layer 2\n",
    "        l_forward_2   = lasagne.layers.LSTMLayer(l_recurrent_1, num_units=hidden_layer[1], learn_init=True, peepholes=True)\n",
    "        l_backward_2  = lasagne.layers.LSTMLayer(l_recurrent_1, num_units=hidden_layer[1], backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_2 = ElemwiseSumLayer( [l_forward_2, l_backward_2] )\n",
    "        '''\n",
    "        # LSTM layer 3\n",
    "        l_forward_3   = lasagne.layers.LSTMLayer(l_recurrent_2, num_units=hidden_layer[2], learn_init=True, peepholes=True)\n",
    "        l_backward_3  = lasagne.layers.LSTMLayer(l_recurrent_2, num_units=hidden_layer[2], backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_3 = ElemwiseSumLayer( [l_forward_3, l_backward_3] )\n",
    "        \n",
    "        # LSTM layer 4\n",
    "        l_forward_4   = lasagne.layers.LSTMLayer(l_recurrent_3, num_units=hidden_layer[3], learn_init=True, peepholes=True)\n",
    "        l_backward_4  = lasagne.layers.LSTMLayer(l_recurrent_3, num_units=hidden_layer[3], backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_4 = ElemwiseSumLayer( [l_forward_4, l_backward_4] )\n",
    "        '''\n",
    "        \n",
    "        #l_reshape = lasagne.layers.ReshapeLayer(l_recurrent_4, (N_BATCH*MAX_LENGTH, hidden_layer[3])  )\n",
    "        l_reshape = lasagne.layers.ReshapeLayer(l_recurrent_2, (N_BATCH*MAX_LENGTH, hidden_layer[1])  )\n",
    "\n",
    "        \n",
    "        #===========================================================================================\n",
    "        # COMMON SETUP\n",
    "        #===========================================================================================\n",
    "        \n",
    "        # Our output layer is a simple dense connection\n",
    "        l_recurrent_out      = lasagne.layers.DenseLayer( l_reshape, num_units=output_num_units[0] , nonlinearity=lasagne.nonlinearities.identity)\n",
    "        \n",
    "        # Now, reshape the output back to the RNN format\n",
    "        l_out_shp            = lasagne.layers.ReshapeLayer( l_recurrent_out, (N_BATCH, MAX_LENGTH, output_num_units[0]) )\n",
    "        \n",
    "        # dimshuffle to shape format (input_seq_len, batch_size, num_classes + 1)\n",
    "        l_out_shp_ctc        = lasagne.layers.DimshuffleLayer( l_out_shp, (1, 0, 2))\n",
    "\n",
    "        l_out_softmax        = lasagne.layers.NonlinearityLayer( l_recurrent_out, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "        l_out_softmax_shp    = lasagne.layers.ReshapeLayer( l_out_softmax, (N_BATCH, MAX_LENGTH, output_num_units[0] ))\n",
    "        \n",
    "        # since we use gaussian noise in input, False means use noise, True means dont use noise\n",
    "        output_lin_ctc_train = lasagne.layers.get_output( l_out_shp_ctc, x, deterministic=False)\n",
    "        output_softmax_train = lasagne.layers.get_output( l_out_softmax_shp, x, deterministic=False)\n",
    "        \n",
    "        output_lin_ctc_val   = lasagne.layers.get_output(l_out_shp_ctc, x, deterministic=True)\n",
    "        output_softmax_val   = lasagne.layers.get_output(l_out_softmax_shp, x, deterministic=True)\n",
    "        \n",
    "        self.all_params      = lasagne.layers.get_all_params(l_out_shp)\n",
    "\n",
    "        # the CTC cross entropy between y and linear output network\n",
    "        pseudo_cost = ctc_cost_2.pseudo_cost(\n",
    "            y, output_lin_ctc_train, y_mask, y_hat_mask,\n",
    "            skip_softmax=True)\n",
    "        \n",
    "        \n",
    "        pseudo_cost_grad = T.grad(pseudo_cost.mean(), self.all_params)\n",
    "        true_cost        = ctc_cost_2.cost(y, output_softmax_train.dimshuffle(1, 0, 2), y_mask, y_hat_mask)\n",
    "        cost             = T.mean(true_cost)\n",
    "        updates          = lasagne.updates.rmsprop(pseudo_cost_grad, self.all_params, learning_rate = self.up_learning_rate)\n",
    "\n",
    "        self.train = theano.function(\n",
    "            inputs = [x, y, y_hat_mask, y_mask],\n",
    "            outputs = [ pseudo_cost.mean(), cost, output_softmax_train ],\n",
    "#             outputs = [output_lin_ctc, output_softmax, cost],\n",
    "            updates=updates\n",
    "        )\n",
    "        \n",
    "        self.predict = theano.function( \n",
    "            inputs=[x], \n",
    "            outputs = [ output_softmax_val] \n",
    "        )\n",
    "\n",
    "        \n",
    "    # x_mask and y_mask is the same\n",
    "    # x_test_mask and y_test_mask is the same\n",
    "    def fit(self, x_train, y_train, x_test,  y_test , x_mask, y_mask, x_test_mask, y_test_mask ):\n",
    "        print \" \"\n",
    "        print \"start training!!!!\"\n",
    "        print \" \"\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        for i in range(self.max_epochs):\n",
    "            self.epochs +=1\n",
    "            t0 = time()\n",
    "            \n",
    "            cs = 0.\n",
    "            pseudo_cs = 0.\n",
    "            for index in range(len(x_train)):\n",
    "                pseudo, cost, output_softmax = self.train( x_train[index] , y_train[index],\n",
    "                                                          x_mask[index], y_mask[index])\n",
    "                cs += cost\n",
    "                pseudo_cs += pseudo\n",
    "                gg = index\n",
    "                if index % 10 == 0:\n",
    "                    print index, pseudo, cost\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "            cs /= len(x_train)\n",
    "            pseudo_cs /= len(x_train)\n",
    "            \n",
    "#             cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "            if self.epochs <= 1:\n",
    "                previous_cs = \"-\"\n",
    "            else:\n",
    "                previous_cs = self.train_history_[-1]['cost']\n",
    "            print \"\\n===============================\"\n",
    "            print 'epoch {0} : pseudo= {1}, cost= {2}, previous_cost= {3}, train_time = {4} s'.format(self.epochs,\n",
    "                                                                                                      pseudo_cs, \n",
    "                                                                                                      cs,\n",
    "                                                                                                      previous_cs, \n",
    "                                                                                                      time() - t0)\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            t0 = time()\n",
    "            \n",
    "#             print np.argmax(output_softmax[:],axis=2)\n",
    "#             print decode_all( np.argmax(output_softmax[:],axis=2) , x_train_mask[gg],  batch_size , True)\n",
    "            \n",
    "            # save model first\n",
    "            # dont know the LER performance yet\n",
    "#             cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "    \n",
    "\n",
    "            label_error_rate = 0.\n",
    "            print len(x_test)\n",
    "            for index in range( len(x_test) ) :\n",
    "\n",
    "                prepre = self.predict( x_test[index])\n",
    "                \n",
    "                label_error_rate += check_all( y_test[index], y_test_mask[index],\n",
    "                                              np.argmax(prepre[0],axis=2) , x_test_mask[index],\n",
    "                                              batch_size)\n",
    "                \n",
    "                if (( index + self.epochs ) % 4 == 0 ):\n",
    "                    ## print actual\n",
    "                    y_actual = decode_all_actual( y_test[index], y_test_mask[index], batch_size , True)\n",
    "\n",
    "                    ## print pred\n",
    "                    y_predict = decode_all_pred( np.argmax(prepre[0],axis=2) , x_test_mask[index],  batch_size , False)\n",
    "                \n",
    "            label_error_rate /= len(x_test)\n",
    "            self.train_history_.append({\"epoch\":self.epochs, \"cost\": cs, \"LER\":label_error_rate})\n",
    "            \n",
    "            print '\\t\\t\\t val_= {0}, test_time  = {1} s'.format(label_error_rate, time() - t0)\n",
    "            print \"===============================\\n\"\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            for a , b in zip (y_actual,y_predict):\n",
    "                print \"Target== \",a \n",
    "                print \"\\tAns => \",b\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            \"\"\"\n",
    "            should use cost do early stopping\n",
    "            \"\"\"\n",
    "            current_cs = self.train_history_[-1]['cost']\n",
    "            current_epoch = self.train_history_[-1]['epoch']\n",
    "            if current_cs < self.best_valid:\n",
    "                self.best_valid = current_cs\n",
    "                self.best_valid_epoch = current_epoch\n",
    "                self.best_params = [w.get_value() for w in self.all_params]\n",
    "                cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "                \n",
    "            elif self.best_valid_epoch + self.patience <= current_epoch:\n",
    "                print \"\"\n",
    "                print \"Early stopping.\"\n",
    "                print self.best_valid_epoch,self.best_valid\n",
    "                print \"Best valid ler {:.6f} at epoch {}.\".format(self.best_valid, self.best_valid_epoch)              \n",
    "#                 for qq in range (len(self.all_params)):\n",
    "#                     self.all_params[qq].set_value( self.best_params[qq] )\n",
    "#                 break\n",
    "\n",
    "            \"\"\"\n",
    "            can not use label error rate do early stopping\n",
    "            \"\"\"\n",
    "#             current_ler = self.train_history_[-1]['LER']\n",
    "#             current_epoch = self.train_history_[-1]['epoch']\n",
    "#             if current_ler < self.best_valid:\n",
    "# #                 print \"********************* Now best ************************\"\n",
    "#                 sys.stdout.flush()\n",
    "#                 self.best_valid = current_ler\n",
    "#                 self.best_valid_epoch = current_epoch\n",
    "#                 self.best_params = [w.get_value() for w in self.all_params]\n",
    "# #                 cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "                \n",
    "#             elif self.best_valid_epoch + self.patience <= current_epoch:\n",
    "#                 print \"\"\n",
    "#                 print \"Early stopping.\"\n",
    "#                 print self.best_valid_epoch,self.best_valid\n",
    "#                 print \"Best valid ler {:.6f} at epoch {}.\".format(self.best_valid, self.best_valid_epoch)\n",
    "#                 sys.stdout.flush()                \n",
    "#                 for qq in range (len(self.all_params)):\n",
    "#                     self.all_params[qq].set_value( self.best_params[qq] )\n",
    "#                 break\n",
    "\n",
    "\n",
    "#     def prediction(self, x, x_mask) :\n",
    "        \n",
    "#         abc =  self.predict(x, x_mask)\n",
    "        \n",
    "#         return np.argmax(abc[0], axis = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# ONE LAYER, Predict\n",
    "\n",
    "\n",
    "    model1L_noNoise_with212 = end_to_end (\n",
    "        input_shape      = (1, x_train.shape[3] ) , # batch of 1, (110, 30, 777, 117)\n",
    "        max_seq_length = x_train.shape[2],\n",
    "        hidden_layer     = [ 250, 250, 250, 250 ], # maximum layer to LSTM 3 layer only\n",
    "        batch            = batch_size, \n",
    "        max_epochs       = 300, \n",
    "        output_num_units = [ len(char_unMap) ],\n",
    "        up_learning_rate = 0.0001, \n",
    "        patience         = 7,\n",
    "        file_name = \"model1L_noNoise_with212\"\n",
    "    )\n",
    "\n",
    "\n",
    "### Saved Model\n",
    "Model name = model1L_noNoise_with212_e119bkp.pkl\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# del model1\n",
    "\n",
    "#with open('model1L_noNoise_with212_e119bkp.pkl', 'rb') as f:\n",
    "with open('model2L_noNoise_with313.pkl', 'rb') as f:\n",
    "    model2L_noNoise_with212 = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "          LER        cost  epoch\n",
      "0    1.037463  693.527587      1\n",
      "1    0.929431  444.461191      2\n",
      "2    0.936294  327.619465      3\n",
      "3    0.949367  307.488394      4\n",
      "4    0.965879  256.820227      5\n",
      "5    0.960974  240.565575      6\n",
      "6    0.969005  214.564571      7\n",
      "7    0.977085  205.577697      8\n",
      "8    0.971238  199.922499      9\n",
      "9    0.971441  193.923938     10\n",
      "10   0.976372  189.355299     11\n",
      "11   0.975772  178.289649     12\n",
      "12   0.974839  171.269371     13\n",
      "13   0.983956  162.201809     14\n",
      "14   0.971800  159.468961     15\n",
      "15   0.975346  174.475906     16\n",
      "16   0.978008  160.842493     17\n",
      "17   0.982517  163.562691     18\n",
      "18   0.983046  165.694678     19\n",
      "19   0.973590  156.399482     20\n",
      "20   0.979604  154.120898     21\n",
      "21   0.982324  145.832030     22\n",
      "22   0.979853  140.024163     23\n",
      "23   0.984354  141.981992     24\n",
      "24   0.988696  137.487691     25\n",
      "25   0.989772  132.827822     26\n",
      "26   0.990599  132.598748     27\n",
      "27   0.990602  133.235277     28\n",
      "28   0.986706  130.886050     29\n",
      "29   0.987981  129.481545     30\n",
      "..        ...         ...    ...\n",
      "113  0.718355   71.722076    114\n",
      "114  0.712640   70.804669    115\n",
      "115  0.714155   70.193334    116\n",
      "116  0.722655   69.624280    117\n",
      "117  0.713633   68.885564    118\n",
      "118  0.720974   68.326506    119\n",
      "119  0.712336   67.889859    120\n",
      "120  0.711871   68.581057    121\n",
      "121  0.715445   68.542987    122\n",
      "122  0.710007   67.701661    123\n",
      "123  0.717602   66.808085    124\n",
      "124  0.712870   66.122876    125\n",
      "125  0.712562   65.754687    126\n",
      "126  0.716633   66.308179    127\n",
      "127  0.721704   65.453000    128\n",
      "128  0.707235   65.011702    129\n",
      "129  0.711980   64.628618    130\n",
      "130  0.715867   63.848114    131\n",
      "131  0.721089   63.542687    132\n",
      "132  0.710514   63.240485    133\n",
      "133  0.708881   62.753889    134\n",
      "134  0.715382   61.964507    135\n",
      "135  0.709380   61.472825    136\n",
      "136  0.698705   61.159648    137\n",
      "137  0.714991   60.858305    138\n",
      "138  0.705912   60.086418    139\n",
      "139  0.722118   59.838921    140\n",
      "140  0.730350   60.000929    141\n",
      "141  0.706627   59.382734    142\n",
      "142  0.716525   58.713104    143\n",
      "\n",
      "[143 rows x 3 columns]\n",
      "count    143.000000\n",
      "mean       0.849809\n",
      "std        0.125831\n",
      "min        0.698705\n",
      "25%        0.718669\n",
      "50%        0.822350\n",
      "75%        0.983072\n",
      "max        1.037463\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f32c3a4f750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHFW9/vHPQwJI2BEEgWiQTWRLQAF/CoRFDMgmLgjq\n",
       "FfRiXEAQUcSrFxRRuVcQEFQQJVwVcGFHtgQJmwgEwyYJECFCCEQQ2WQNeX5/nDOmaKYn3TPTU1XT\n",
       "3/frNS+61n66mPSZOt+qU7JNCCGE0JvFyg4QQgihuqKRCCGE0FQ0EiGEEJqKRiKEEEJT0UiEEEJo\n",
       "KhqJEEIITUUjEUL4N0mTJB1ddo5QHdFIhMqTNFvSc5KeKfycVHauvkgaL+mhfm770cLnfE7SgsL0\n",
       "04OdtYHzTwhANBKhHgzsanvZws8XeltR0ohe5rX1e76o9ZW1s8922P5Vz+cEdgYeLnzu5drJ2k8d\n",
       "+2yhfqKRCLUmaT9JN0g6XtLjwFGSzpD0Y0mXSnoWGC9pA0lTJf1T0l2SdivsY1Lj+r28z1RJ35Z0\n",
       "A/Av4C2S9pd0t6SnJf1V0qfzuksDlwGr9/z1L2m13LZ8VdIsSY9L+rWkFRf1ERtyvCarpNUlnSvp\n",
       "75Lul3RQYf2jJP1G0pk5x12SNi8sHyfpz3nZOcDr2vxfEIa5aCRCXfT11+0WwF+BNwDH5HX3AY62\n",
       "vQxwC3AxcDmwCnAQ8CtJ6xX2UVz/hibv8zHgP4FlgL8B84D35b/u9wd+IGmc7X8BE4C5PX/9234U\n",
       "+AKwO7AN8Ebgn8Ap7R2G12S9MX+26cDqwA7AIZJ2Kqy/G3A2sDxwEXAygKQlgAuAM4EVgd8CHyC6\n",
       "m0JBNBKhDgRckM8Cen4+VVg+1/YpthfYfoH0JXeB7Rvz8rHA0ra/Z3u+7auBS0hftj3+vb7tF3vJ\n",
       "YGCS7Rn5febbvtT2A3mba4Erga0LmRtNBL5ue67tl4FvAh9ss8uo8bNtAqxs+9s50wPA6cBHCttc\n",
       "Z/typ4HafglsmudvBYy0faLtV2yfS2pQQ/i3kWUHCKEFBvaw/Ycmy3srEM8pvF69l3X+luf37H8O\n",
       "i/aqfUjaGTgSWJf0B9co4I4+th8DnC9pQWHefGBV4JEW3r9HMeubSd1a/yzMGwFcW5ieV3j9HPC6\n",
       "3DCtDjzcsO+/ETWJUBCNRBgOeuseKc6bC4yWJC8c9vjNwMz+vo+kJYFzSV1QF9p+RdL5LPyC7S3T\n",
       "g8D+hbOA/iru+0HgAdvrtbBuo0eANRrmvRmYNYBsYZiJ7qZQF+38ddu47p9If0F/RdLiksYDuwLn\n",
       "tLnv4npL5J/HgQX5rKJYB5gHvF5S8WqknwDfkfQmAEmrSNq9xffuLQPAzcAzkr4iaSlJIyRtJOnt\n",
       "TdYvuhGYL+kL+bjsBbyjzTxhmItGItTFxQ33SZyb5/d2Xf+r5uX+/91Il5M+Rircftz2vX3sozfF\n",
       "fT5DKkT/BniCVN+4sLB8JqlYfL+kJyStBpxIKhxfme93uJFUdG/5fXv5bAtIDd5Y4P78+U4Dlutt\n",
       "/eL+bL8E7AXsB/wD+DDp7CiEf1MnHzok6efA+4C/2964yTonkf7xPgfsZ3t6nj8beBp4BXjZdiv/\n",
       "mEIIIQyiTp9JnEG6FLBXknYB1rG9LvBp4MeFxQbG2x4XDUQIIZSjo42E7etI14I3szvpGm1s3wSs\n",
       "IGnVwvK4yiKEEEpUdk1iDV59WeEcFl5tYWCKpGmSDhjyZCGEECpxCWyzs4V3254raRVgsqSZ+cwk\n",
       "hBDCECm7kXgYGF2YXjPPw/bc/N/H8vXnWwCvaiQkxfABIYTQD7Zb6s4vu5G4CDgQOEfSVsCTtudJ\n",
       "GgWMsP1MHixtJ9IQBq/R6getGklH2T6q7Bz9Vef8kb0ckb0cvWVv5w/sjjYSks4GtgVWVhpb/0hg\n",
       "cQDbp9q+VNIukmaRRtbcP2+6GnBeHo15JPAr21d2MmsJxpQdYIDGlB1gAMaUHWAAxpQdYADGlB1g\n",
       "AMaUHWAAxgxk4442Erb3aWGdA3uZdz/p5qAQQgglKvvqpm42qewAAzSp7AADMKnsAAMwqewAAzCp\n",
       "7AADMKnsAAMwaSAbd/SO607L47XVsiYRQghlaee7M84kSpIHmautOueP7OWI7OUYaPZoJEIIITQV\n",
       "3U0hhNBlorsphBDCoIhGoiR17uOEeueP7OWI7OWImkQIIYSOiZpECCF0mahJhBBCGBS1byQkRpSd\n",
       "oT/q3McJ9c4f2csR2csRNQlYquwAIYQwXNW+JgFe1ebvZWcJIYS66LaaxKiyA4QQwnAVjURJ6tzH\n",
       "CfXOH9nLEdnLETWJmjYSIYRQB8OhJrGtzbVlZwkhhLqImkQIIYRBEY1ESercxwn1zh/ZyxHZy1Hp\n",
       "moSkn0uaJ+nOPtY5SdJ9km6XNK4wf4KkmXnZ4X28TS0biRBCqIOO1iQkbQ08C/yf7Y17Wb4LcKDt\n",
       "XSRtCZxoeytJI4B7gB2Bh4FbgH1sz2jY3uCJNqd17EOEEMIwU5mahO3rgH/2scruwJl53ZuAFSSt\n",
       "BmwBzLI92/bLwDnAHk32EWcSIYTQIWXXJNYAHipMz8nzVm8yvze1bCTq3McJ9c4f2csR2ctR6ZpE\n",
       "iwY61HctG4luJiGpEr97IYRFGFny+z8MjC5Mr0k6a1i8Yf7oPL8X498vXTM/TzwJ3GZ7KixsQas4\n",
       "bXtqlfJ0On9qFLbaEz62Exw4ARgpnXYV3HoTnLoA2BJOeQmuuBYuuhbYG363B9z/J/jK0cCy8P1D\n",
       "Yall4PNH28yp0vEYyukeVcnT6nTPvKrk6aZ/r/n1fiSzaUPHb6aTNAa4uIXC9VbACblwPZJUuN4B\n",
       "mAvcTPPC9ak2n+nohwivIiEb59cjgW2BCcBmwLrA74Dvk87yvgp8CFiGdBHD+cDJwIvAAcB44FbS\n",
       "/+ONgfcDSwLnAjeQ6lbvAV4GLgP+BXwQuA6YaPNopz9vCMNNO4VrbHfsBzib9CX/EqnG8ElgIjCx\n",
       "sM7JwCzgdmCzwvydSQ3FLOCIJvs3+P86+Rk6eGzGl52h/cxeC/wT8AtwxWPgqeB54FvA3wBPAG8I\n",
       "/gH4CfBj4KPAq4IXa/E9FgOPbJi3PHjxwvTS4KPBD4Df2g3HPrJH9sHMnr76W9u+o91NtvdpYZ0D\n",
       "m8y/jPSX46JETaKDJN5IurJsN2BL4FTgTfA/28FOTwD32/y1YbMvSnwLeNnm2Xbez2YBsKBh3lMN\n",
       "0/8CviHxV+AaifPyNjfa/LKd9wsh9G04jN10mc0uZWfpFAmRunD+H6k7Z0MW1pJ+bHNOh953MdJZ\n",
       "39Gkxvpi4HKbpzvxfv0lsRWwOekijCOBrWxmlZsqhGprp7up7ML1YBiWZxL5S/rbwH8AJvXB3wr8\n",
       "HngBWA74kcQbbE6SWIrUgNxq85qWX2KkzfzG+b2stwSwE3AosDTwbpuZg/SxBp3Nn4A/AUgsC3yX\n",
       "VAMJIQyC4XAZYi0bib6uXc5nDyeQCsLbAW+y2dfmOJsrbK6xuRjYGjhQ4npgHnAJ8IO8fXF/mwCP\n",
       "SLy/r/eUOIRUQzqcdAPju5o1EBW9bvwEYCuJd/a1UkWztySyl6Obs8eZRD8Ur+7pxL6B7wDvArZv\n",
       "7I8vspkt8S5gG+BqUr/8ZOD7EofZWGI94HJSLeEnEjfbPCyxHKnOcAfwQF6+AfBOm/s68dk6zeY5\n",
       "iW+QPv/Wub4RQhiA4VCTeMDmLUP7vlwA/K6vImm+NHQ74C3AisAPc8G1cb1RwPM9jY7E14GPAONt\n",
       "Hu9HthWBKaTG8x5SHeObNj+T+G9Sg/It0nAo9wFrAWNIZw6ftnm+3fesEokRwJWkS2U/3lcjG0K3\n",
       "aqcmMRwaiXk2qw3dezKOdE3/9TbbNVlnMeAM0hf0n4BNgV/Y/LCwzkjgi8BRpFrDF0iNymeBbW0e\n",
       "GUDGJUhnBesA/7K5vPCeU0mF8P/MXVbks4pnOnV2NNTy5z+edH/FrnU9MwqhU7qtkXjGZrmhe0/O\n",
       "Bu4CDgM2tJnbsFzAScBY4L25C+SdwC+B9WxekXgDXHId7DoH+AywPemv++eBbWwe7GD+5YHF7D4H\n",
       "XmxhPwvvnK0qiS8AnwbeUTxDqkP2ZiJ7OYZb9sqMAjtERjUWalslsUo720q8hfTX6Q+BC4EPNyxf\n",
       "BvgRqZ6wq81zADY3An8H9sjvdzo8fjuwo819NqcC6wNbdLKByFmeGmgDUSM/BO4Ejis7SAh1NRzO\n",
       "JF4GlrF5qb1tWQ64Hzje5jsNy0aSCrlrkvrt7yZ1G30aeMLmaxLvBb5ls2Xe5n2kBmIq8EWbJxr2\n",
       "+UHgEFIt4HPAlu1mDu3LZ07TgS/ZnF92nhCqoNu6m54Cxtg82d62HEV6bsXmwB75evue7qJTgLVJ\n",
       "3UbrAJsAW5EGGlzP5tHckDxMOmv4OPAJ4FM2VzV5v5GkBmcF0qWld7f5cUM/5RvuLgH+CzhtuNRe\n",
       "QuivbruZ7jnSlTwtNxISKwMHAe8gFZXPygXp5/P8bUhf5E81bLdYz2WVNvMlfke69PQh0pnBvGbv\n",
       "mdc/DFjC5u4693FCvfpobf4k8W7g18D20sqn249PLjtXf9TpuDeK7OUYaPbh1Ei046vAOTb3A/dL\n",
       "7AA8QbrP4AHgPb1dOtnLdfc/Io1m+jWbFxb1pjbntpkzDBKbmRJbAlPgoHeT7icJISzCcOhuuhP4\n",
       "mM0drW3DmqQRZzfqucw0dzEtYfNi59KGKpD4D+ADdtPH4YYw7HXb1U3tnkl8A/hp8T6EPCJuNBDd\n",
       "4QJgvMRKZQcJoQ6GdSORxyOaKrFTnl4H+ADwP0OYr1d1HgsG6ps/jWL7mz+Tfg9qp67HHSJ7WYbD\n",
       "M64Hqq8zibWAccAvJTYm3bB2QuPlqaHb3HEVsG/ZKUKog+FQk/gtaRyl37x2OZ8i3c18CemGqsWA\n",
       "ddp9EE4YXiSWJI12u4nNw2XnCWGodeslsL3ZHrja5myJ15NuhIsGosvZvChxPrA3aYynEEITw7a7\n",
       "KV+xtD3wBwCbk23OGuJsTdW5jxPqnT9nP4sadjkNg+NeS92cvaONhKQJkmZKuk/S4b0sX1HS+ZJu\n",
       "l3STpA0Ly2ZLukPSdEk39/E2zc4k1gdeIt33EEKja4DVJdYvO0gIVdaxmoSkEaTnGexIGr7iFmAf\n",
       "2zMK6/wv8LTtoyWtD5xie8e87AFgc9tNi8y5JnE0MN/mW69exudIo3/uP9ifLQwPEscDT9scVXaW\n",
       "EIZSVe6T2AKYZXu27ZdJD7VpvIFpA9KwFti+BxgjaZXC8lY+RLMzie3IXU0hNHEWsG9/RxEOoRt0\n",
       "spFYgzSmUY85eV7R7cBeAJK2AN5MGnkVwMAUSdMkHdDH+7ymkcgP/dmO3ABVUZ37OKHe+QvZbyX9\n",
       "IbJ5eWnaM0yOe+10c/ZOXt3USj/W94ATJU0njfs/HXglL3u37bn5zGKypJm2r3vtLsbtDWOXkiYd\n",
       "RRrk7zbwk8A/QetIrNMzuFXPwYrp7p5eSNvCqTfAp/cFplUl3yKmx5KGo69KnpangbGSKpOnW6YL\n",
       "r/fLk7NpQydrElsBR9mekKePABbYPraPbR4ANrb9bMP8I4FnbR/XMN/gj5Ie8LPvwvkcCSxvc+jg\n",
       "faIwHEmsB1wHvLWLHsYUulxVahLTgHUljZG0BOma9IuKK0haPi8jdyldY/tZSaMkLZvnLw3sRDrT\n",
       "6E1vNYkPAOcN3kcJw5XNvcDvgKZ/vITQzTrWSNieDxwIXEF6stuvbc+QNFHSxLza24A7Jc0E3gsc\n",
       "nOevClwn6TbgJuAS21c2eatXNRIS6wKrAH8c7M80mOrcxwn1zt9L9q8Bu0hsU0Kctgyz414b3Zy9\n",
       "o3dc274MuKxh3qmF1zfCa69Tt/0Aqe+1FY1nEh8Azu/l2Q8h9MrmKYmDgNMkxrbybJAQusVwGLtp\n",
       "c+B0m83SPG4mPQRoSrnpQt1IXA981+b3ZWcJoZOqUpMYKv8+k5B4E/AW0t20IbTrJmCjskOEUCXD\n",
       "qpEgdTVdZPNyiXlaUuc+Tqh3/j6y3wVsPIRR2jZMj3vldXP2YdNISCwPHAacVnKeUF93UvFGIoSh\n",
       "NhxqEksDjwOnA0vZ9HV3dghNSYwC/gEsV4ez0RD6q52axHB4nsQLwOuADwMbLmLdEJqyeU5iDrAu\n",
       "6bLtELpe7bub8qWuzwNH2Pyj7DytqnMfJ9Q7/yKy30mFi9fD+LhXWjdnr30jkW0NnFl2iDAsVL54\n",
       "HcJQqn1NotV+tRBaIfEh4KM2e5adJYRO6bb7JEIYTJXubgphqEUjUZI693FCvfMvIvss0mNNlx6i\n",
       "OG0Zxse90ro5ezQSIRTYzCc9dvdtZWcJoQqiJhFCA4lfAFfb/LzsLCF0QtQkQhiYO4FNyw4RQhVE\n",
       "I1GSOvdxQr3zt5B9KvCezidp3zA/7pXVzdmjkQjhtaYBr5dYq+wgIZQtahIh9ELiDOBWm5PLzhLC\n",
       "YIuaRAgD93tg17JDhFC2aCRKUuc+Tqh3/hazTwbeVbX7JbrguFdSN2fvaCMhaYKkmZLuk3R4L8tX\n",
       "lHS+pNsl3SRpw1a3DaGTbJ4CbgZ2KDtLCGXqWE1C0gjSTUk7Ag8DtwD72J5RWOd/gadtHy1pfeAU\n",
       "2zu2sm3ePmoSoWMkDgXeavPpsrOEMJiqUpPYAphle7btl4FzgD0a1tkAuBrA9j3AGElvaHHbEDrt\n",
       "98CuEkuUHSSEsnSykVgDeKgwPSfPK7od2AtA0hbAm4E1W9y21urcxwn1zt9qdpt7gNuAz3c0UBu6\n",
       "4bhXUTdn7+ST6Vrpx/oecKKk6aS7XKcDr7S4LQCSJgGz8+STwG22p+Zl4wFiOqaL0z1aW3+vc+Dc\n",
       "49JQHdqoAvnHkm72q8zxbHUaGCupMnm6Zbrwer88OZs2dLImsRVwlO0JefoIYIHtY/vY5gHSA182\n",
       "amXbqEmEoSDxQ0A2B5adJYTBUJWaxDRgXUljJC0B7A1cVFxB0vJ5GZIOAK6x/Wwr24YwhI4C9pZ4\n",
       "a9lBQhhqHWskbM8HDgSuID1U/te2Z0iaKGliXu1twJ2SZgLvBQ7ua9tOZS1Dnfs4od75282en53+\n",
       "U+CTHQnUhm467lXSzdk7WZPA9mXAZQ3zTi28vhFYv9VtQyjR2cAlEl+1WVB2mBCGSozdFEILJATc\n",
       "BRxg88ey84QwEFWpSYQwbNiYdDaxT9lZQhhK0UiUpM59nFDv/API/mvgQ1Jnu2n70qXHvXTdnD0a\n",
       "iRBaZHMf6cbObcvOEsJQiZpECG2QOAxYL8ZzCnUWNYkQOucy0sCTIXSFaCRKUuc+Tqh3/gFmvxtY\n",
       "VuJNgxSnLV183EvVzdmjkQihDfkqp2uIukToElGTCKFNEgcBm9r8Z9lZQuiPqEmE0FlTiTOJ0CWi\n",
       "kShJnfs4od75ByH7X4AVpaF/xkmXH/fSdHP2aCRCaFMeu+k64mwidIGoSYTQDxKHABvYTFzkyiFU\n",
       "TNQkQui8qcSZROgC0UiUpM59nFDv/IOU/Q5gNYmVB2FfLYvjXo5uzt6vRkLSmgN50xDqLtclpgOb\n",
       "l50lhE7qsyYhaXPgLcDdtv8iaTTwDWCC7VLuOC2KmkQok8T3gSdsvlN2lhDaMSg1CUnfBn4J7AVc\n",
       "JOk44FrSsATrDUbQEGpuGnEmEYa5vrqb9gLG2d4HeAfwGWA72yfYfmFI0g1jde7jhHrnH8TstzLE\n",
       "jUQc93J0c/a+GokXexoD208A99me3c7OJU2QNFPSfZIO72X5ypIul3SbpLsk7VdYNlvSHZKmS7q5\n",
       "nfcNYYj8FVhhqIvXIQylpjUJSU+Rupd6bE26gQjAtnfvc8fSCOAe0rDKDwO3APvYnlFY5yhgSdtH\n",
       "SFo5r7+q7fmSHgA2zw1Us/eImkQolcTVwPdsrig7Switaue7s6/HMO7RMH1c4XUrd+BtAczqOfuQ\n",
       "dE7e54zCOo8Am+TXywH/sD2/sDwagFB1PV1O0UiEYamv7qbptqf29gPMbmHfawAPFabn5HlFPwU2\n",
       "lDQXuB04uLDMwBRJ0yQd0ML71Uqd+zih3vkHOfuQFq/juJejm7P3dSYxFRiX3+Qq2zsUll3Qs6wP\n",
       "rZxtfA24zfZ4SWsDkyVtavsZ4F22H5G0Sp4/0/Z1jTuQNImFjdaTeX9T87LxADEd08XpHoOzv91G\n",
       "wEWbD2H+saR/m5U5nq1OA2MlVSZPt0wXXu+XJ2fThr5qEtNtj2t83dt0k+23Ao6yPSFPHwEssH1s\n",
       "YZ1LgWNs35CnrwIOtz2tYV9HAs/aPq5hftQkQqkkFgOeANaxebzsPCG0op3vzk4OyzENWFfSGElL\n",
       "AHsDFzWsM5P8vGBJqwLrA/dLGiVp2Tx/aWAn4M4OZg2hXwp3Xr+97CwhdEJfjcQqkg6V9KXi657p\n",
       "Re04F6APJBX07gZ+bXuGpImSekbO/A7wdkm3A1OAr+SrmVYDrpN0G3ATcIntK/v9KSuozn2cUO/8\n",
       "Hch+AfAlqfMXWsRxL0c3Z++rJnE6sGwvryEVnBfJ9mXAZQ3zTi28fhzYrZft7if1vYZQB6cA+wMf\n",
       "JY1SEMKw0a/nSUj6ou0fdCBPuzmiJhEqQWILUnfqhjb/KDtPCH1p57uzv43EQ7ZHt73hIItGIlSJ\n",
       "xEnA4jafLTtLCH2pSuE69KHOfZxQ7/wdzH4s8GGJER3afxz3knRz9mgkQhgkNg8D81j0PUQh1EZf\n",
       "90k8S/Mb4kbZ7thfS62K7qZQNbnL6RGb75adJYRmBqW7yfYytpdt8lN6AxFCRU0G3lN2iBAGS3Q3\n",
       "laTOfZxQ7/wdzj4V2EJiVCd2Hse9HN2cPRqJEAaRzTOkO7C3LjtLCIOhX5fAVkXUJEIVSfw3sJzN\n",
       "YWVnCaE3cQlsCOWKukQYNqKRKEmd+zih3vmHIPstwJoSg/4+cdzL0c3Zo5EIYZDZzAc+CPxGYpey\n",
       "84QwEFGTCKFDJLYkjef0UZspZecJoUfHx26qimgkQtVJfBLY2eZDZWcJoUcUrmugzn2cUO/8Q5z9\n",
       "UmBHicUHY2dx3MvRzdmjkQihg2weBWYB7yo7Swj9Ed1NIXSYxDeBUTZfLjtLCBDdTSFUze8hrnIK\n",
       "9RSNREnq3McJ9c5fQvZpwCoSYwa6ozju5ejm7B1tJCRNkDRT0n2SDu9l+cqSLpd0m6S7JO3X6rYh\n",
       "1IXNAtKz3uNsItROx2oSkkYA9wA7Ag+T7kLdx/aMwjpHAUvaPkLSynn9VUnPsehz27x91CRCLUh8\n",
       "GPgssENuNEIoTVVqElsAs2zPtv0ycA6wR8M6jwDL5dfLAf+wPb/FbUOok0uAkcD/DdblsCEMhU42\n",
       "EmsADxWm5+R5RT8FNpQ0F7gdOLiNbWutzn2cUO/8ZWS3eQ7YifTH0IUSr+vPfuK4l6Obs48cpBy9\n",
       "aaUf62vAbbbHS1obmCxp03beRNIkYHaefDLvb2peNh4gpmO6ON1jqN8ftCUsfSI8eyjwZUnX9WN/\n",
       "Y0kPNqrM8Wz98zNWUmXydMt04fV+eXI2behkTWIr4CjbE/L0EcAC28cW1rkUOMb2DXn6KuBwUuPV\n",
       "57Z5ftQkQu3kq5xuBcbZPFhynNCFqlKTmAasK2mMpCWAvUmDnRXNJBWnkbQqsD5wf4vbhlBLNrOB\n",
       "HwLfLzlKCIvUsUYiF6APBK4A7gZ+bXuGpImSJubVvgO8XdLtwBTgK7afaLZtp7KWoc59nFDv/BXJ\n",
       "fizpWdjbt7NRRbL3S2QvR5VrEti+jHR9eHHeqYXXjwO7tbptCMOFzfMSBwKnS4y1ebrsTCH0JsZu\n",
       "CqFEEj8hjev0H2VnCd2jKjWJEMKifQnYUuIjZQcJoTfRSJSkzn2cUO/8Vcpu8y/go8CJEiMWtX6V\n",
       "srcrspdjoNmjkQihZDbTSKMPvLPsLCE0ippECBUg8S1gSZsYzDJ0XNQkQqifi4Hdyw4RQqNoJEpS\n",
       "5z5OqHf+ima/FVheYt2+Vqpo9pZE9nJETSKEYSAPH34xTe4bCqEsUZMIoSIkdgUOsxkvsRSwWL76\n",
       "KYRBFTWJEOrpKmCcxM+AR4HTS84TQjQSZalzHyfUO39Vs9s8D3wXuBd4D7BT470TVc3eishejkqP\n",
       "3RRCaI/N93peSzwCbEZ6fG8IpYiaRAgVJfED4HGbY8rOEoaXqEmEMDxcSep2CqE00UiUpM59nFDv\n",
       "/DXKfi2wucQyPTNqlP01Ins54j6JEIapfPnrLcC2EpL4Ehy2Rdm5QneJmkQIFSZxBLAmsCQwDlgZ\n",
       "uJR0P0XcQxH6JWoSIQwfVwKfA0YD2wKbAKOAByV+JbFXmeHC8BeNREnq3McJ9c5fs+zTgU8Bu9k8\n",
       "Cxpn8wlgU1LN4oR2n5Ndlpod91fp5uwdvU9C0gTgBGAEcLrtYxuWH0Z64EpPlg2AlW0/KWk28DTw\n",
       "CvCy7eiLDV0nj+n0817mzwFOlXgWOFriapv69h2HyupYTULSCOAeYEfgYVIBbh/bM5qsvytwiO0d\n",
       "8/QDwOa2n+jjPaImEbpaviP7DuBLNpeXnSfUQ1VqElsAs2zPtv0ycA6wRx/r7wuc3TAvGoAQ+mDz\n",
       "CnAk6WxibYlfSJxbdq4wfHSykVgDeKgwPSfPew1Jo4D3wqt+uQ1MkTRN0gEdS1mSOvdxQr3zD8Ps\n",
       "5wGLA9OAB4D3Fu+tqIpheNxroco1iXb6sXYDrrf9ZGHeu2w/ImkVYLKkmbava9xQ0iRgdp58ErjN\n",
       "9tS8bDxATMd0cbpHVfK0OT0WeM1yiV1g07fDHU+Dtwa2kfRcBfL+exoYK6kyebpluvB6vzw5mzZ0\n",
       "siaxFXCU7Ql5+ghgQWPxOi87H/i17XOa7OtI4FnbxzXMj5pECA0k/gt4vc2hZWcJ1VSVmsQ0YF1J\n",
       "YyQtAewNXNS4kqTlgW2ACwvzRklaNr9eGtgJuLODWUMYTqaQLhgJYcA61kjYng8cCFwB3E06U5gh\n",
       "aaKkiYVV9wSusP18Yd6qwHWSbgNuAi6xfWWnspahzn2cUO/8XZD9VmC0xKodjtOWLjjulVTlmgS2\n",
       "LwMua5h3asP0mcCZDfMeIPW9hhDaZDNf4hpge+BsiXcAT9vcU3K0UEMxdlMIw5DEgaSxnn5BGuvp\n",
       "Apt9y00VqqKd785oJEIYhiTeCtxAGrHgC8CPgdVsXiw1WKiEqhSuQx/q3McJ9c7fJdnvIY37tK/N\n",
       "OaQLP0piINGWAAAQEklEQVR9gFGXHPfKGWj2aCRCGIZsbLOjzZQ861zgAz3LJUbnIT1C6FN0N4XQ\n",
       "BSRGk84s3kgaSPNPwAXAJ2xeLjPbYJD4InDycPgsQyG6m0IIr2LzEPBXYHfSMB4HAssAF0iMKjPb\n",
       "QEm8CTge2LrsLFUjsZLErgPZRzQSJalzHyfUO38XZz8P+BVwmc3PSd1PzwAnDkK0Rergcd8OWEBq\n",
       "ADuixr8zX4crXzPUfDuikQihe5xFaiS+BJC7Zj4H7CUxpsRcAzUeOA3YXYqRo3tIrAHsByOXlVix\n",
       "3/uJmkQI3U3iO8CKNp8tO0t/SMwGdibduLubHUP4AEicAjwHvBs43Obahcta/+7s6B3XIYRa+AFw\n",
       "j8QxwAuQBggE/glcYXNpmeH6IrEWsCQwkzT+2+60Mc6bxGrAvOH2VD+JNwMfAd4KLEd6Nvq1fW7U\n",
       "RHQ3laTGfZxAvfNH9lezeQz4GfBL4C+kxw1fBfwNOF1in/TevFHiPImdF+ZhpMR/SyzV3+wSS0os\n",
       "3TBvV4mVW4g/Hpiav+Qvou8HmzW+73KkceU+VpgnifVbzd7i+ywhcdyiunzy8V2rv+/T4BDgp+n/\n",
       "7fHPAxv3d0fRSIQQAL4PPAbsbPMFmzNtjieNwHx8Psv4M+lM4wSJxfN2nwK+CXy+P28qsQLpL9zJ\n",
       "UurZkNiUdHnuoYX1Vpd4VOJiiU8Vrsjajvx8jbyfdSRWb/HtDwIeAQ6X/v1d+GHgLxJr9+fzNMo1\n",
       "kh8DB0Pzq4wkliWN3jugInPBBOC36eX995POJPolahIhhD5JbAycDHwDuI70ZfYb0iOJ7yF9mZ8A\n",
       "rGfzZLP99LLfFYArSSM9vxW4HjiGdA/HFGB/4E02L0ocS+oC+wPpL//VSF1LNwI72Nyb9zkJWI80\n",
       "ZtVM0hMvtwQOsrmr8N7Lki4J3pr02OQjSWdPM0hnFw/b/GcLn2FF4G02NzRZfijwH8AkYEs7nZU1\n",
       "rLMY6cqzJ4BdgG0HMhhjLljfCaxi80rO+CCwvM2CtE4b353Ot2bW8SfFLz9H/MRPN/2ANwfPBf8I\n",
       "fHqe93PwMW3sYzHwteCTwAKvAZ4H/j/wlDxvMvhj4OXA/wCPydsKfHhe/2GwCvtdCrwX+Jfgm8Hf\n",
       "Bn8d/BfwqMJ6R4B/lV9/GHw9+L/BvwGvlN/vzb3kXrNh+qfgl8Dv6WXdj+Tj9Cbw6nmfI3tZ72jw\n",
       "DeAlwN8Df7+XdUaCl2vx2H4MfF7DvIfAb8mvD23nu7P0X7iB/bK2/kGr9gOMLztDt+aP7IORw2eD\n",
       "nwGvlqdH5y/BNxbWWQH8Z/DmjdnBe4NvBS9WmLcX+NnCl9me4BvBh4HP6iXDnuCDW8gq8C/Ap+fX\n",
       "7wL/HbxBXj4CPAv8dKEh+i74Rwv38brtwf8LNnjXvM7GuaF6X97fZoX33D83EBsV5v0ZvHVDru+C\n",
       "ZxSO49p5X0s2fIZTwDOLDV1h2Tbg3xSmzwB/vvg7A/59Pl4jwQ9GI1GDn6r8Y+/G/JF9MHJ4NfD2\n",
       "DfOOAV8GHpGnTwPfmRuDkT3ZwUuC/wrerpf9Ll14nb/Q/CR43ADzLgu+FzwHfDf40w3L93z1F6tX\n",
       "AT8B/jx4N/jt9eCpuUGYl7/MLwcflNffC/xYnnd+/st9/Yb3+Db4e/n1iHx8bgav3LDeZPA+hemt\n",
       "SWdM54FP6eWz/SA3XlvkhudB8FuLvzO5MfoG+APg69v57oyaRAhhUORi9hWkGsMVpKulNiL1t19o\n",
       "pzu7JQ4B3mPzvhb2+WVge3vhFVUDyPdG0lMvb7cXfcmrxJ6k+y/WBO4DvmLzksRBwOGkexA2dB4v\n",
       "SmIDYC1gJeAap6FQivt7J+mmv02AH5KOzW42zzSs9yHgMGAvUp3i9vx+VwO3AZ9z4bJkiTtINYjX\n",
       "5fWuAdYsfkaJfYH3A6sAPwad0+p3ZzQSIYRBI7EKcAswCjjA5kKJ9YA/AhOB1YGvk774/9LC/gQs\n",
       "bvNSB2O3JWc6jjS8yeQ2thsBzCPd+b4tsI3NU72stwTp3pV9gUeBu2w+lJdtSyq0r23zvMQbgHuB\n",
       "N5Masl+SCtYfb9jnRqQLA54F1gK91Op3Z0cvgZU0QdJMSfdJOryX5YdJmp5/7pQ0X9IKrWxbd3W+\n",
       "Vh/qnT+yd47TPRd7kEZkvTDPuxf4L7jgCNIItJ9vpYHI27oKDUTxuOdMh7bTQOTtXgEuJx2fnXtr\n",
       "IPJ6L9l8nnQG803gM4Vl15DOLD6YZ40Hrs37OgX4Iukqrcbs95Aa7p+43ZFyO9h3OgKYBYwBFied\n",
       "Jm3Qx/q7AlPa2ZaoSUT+yF6bn8huSFdxrTnAfewFvja/PhV8SH79evAjjftnYS3o8J76RzvfnR3r\n",
       "bpL0TuBI2xPy9Fdzsu81Wf8s4CrbP2t12+huCiF0m1z7eRDYnnSX+V7O41VJjLSZv+h9VON5EmvA\n",
       "qwo3c/K815A0inTTy7ntbhtCCN3EqbtoEvAtYHlY2HXXSgPRrk42Eu2couwGXG+7527N+lbTW1T1\n",
       "vuVFqXP+yF6OyD6oTifVJa52vou6mYFm7+QosA8DowvTo0lnBL35CKli3/a2kiYBs/Pkk8Bttqfm\n",
       "ZeMBYjqmi9M9qpKnzemx5LGKKpKn5WlgrKTK5KnztM1fpfNuhnvuhyPoa/3C6/3y5Gza0MmaxEhS\n",
       "RX0HYC5wM7CP7RkN6y0P3A+safv5NreNmkQIoSvlS2VfttvveWnnu7NjZxK250s6kHRTzQjgZ7Zn\n",
       "SJqYl5+aV90TuKKngehr205lDSGEuvEQXRocN9OVRNL4wml47dQ5f2QvR2QvR2/Zq3J1UwghhJqL\n",
       "M4kQQugycSYRQghhUEQjUZIKXnfdljrnj+zliOzlGGj2aCRCCCE0FTWJEELoMlGTCCGEMCiikShJ\n",
       "nfs4od75I3s5Ins5oiYRQgihY6ImEUIIXSZqEiGEEAZFNBIlqXMfJ9Q7f2QvR2QvR9QkQgghdEzU\n",
       "JEIIoctETSKEEMKgiEaiJHXu44R654/s5Yjs5YiaRAghhI6JmkQIIXSZqEmEEEIYFB1tJCRNkDRT\n",
       "0n2SDm+yznhJ0yXdJWlqYf5sSXfkZTd3MmcZ6tzHCfXOH9nLEdnLUdmahKQRwMnABOBtwD6SNmhY\n",
       "ZwXgFGA32xsBHywsNjDe9jjbW3QqZ4nGlh1ggOqcP7KXI7KXY0DZO3kmsQUwy/Zs2y8D5wB7NKyz\n",
       "L3Cu7TkAth9vWD6c6w0rlB1ggOqcP7KXI7KXY0DZO9lIrAE8VJiek+cVrQusJOlqSdMkfbywzMCU\n",
       "PP+ADuYMIYTQxMgO7ruVy6YWBzYDdgBGATdK+pPt+4B3254raRVgsqSZtq/rYN6hNqbsAAM0puwA\n",
       "AzCm7AADMKbsAAMwpuwAAzCm7AADMGYgG3eykXgYGF2YHk06myh6CHjc9vPA85KuBTYF7rM9F8D2\n",
       "Y5LOJ3VfvaaRkFTba3glfaLsDANR5/yRvRyRvRwDyd7JRmIasK6kMcBcYG9gn4Z1LgROzkXuJYEt\n",
       "geMljQJG2H5G0tLATsA3G98g7pEIIYTO6lgjYXu+pAOBK4ARwM9sz5A0MS8/1fZMSZcDdwALgJ/a\n",
       "vlvSW4DzJPVk/JXtKzuVNYQQQu9qfcd1CCGEzqrtHdet3KhXFZJG5yu4/pJvGvxCnr+SpMmS7pV0\n",
       "Zb5vpJIkjcg3Nl6cp2uRXdIKkn4naYakuyVtWaPsR+TfmTslnSVpyapml/RzSfMk3VmY1zRr/mz3\n",
       "5X/DO5WTeqEm+f83/97cLuk8ScsXllUmf2/ZC8u+JGmBpJUK89rKXstGopUb9SrmZeCLtjcEtgI+\n",
       "n/N+FZhsez3gqjxdVQcDd7PwqrW6ZD8RuNT2BsAmwExqkD3X8g4ANrO9ManL9iNUN/sZpH+PRb1m\n",
       "lfQ2Uo3ybXmbH0kq+7uot/xXAhva3hS4FzgCKpm/t+xIGg28B/hbYV7b2cv+H9NfrdyoVxm2H7V9\n",
       "W379LDCDdM/I7sCZebUzgT3LSdg3SWsCuwCns/AGx8pnz3/5bW3755DqZLafogbZgadJf1yMkjSS\n",
       "dIn4XCqaPV+e/s+G2c2y7gGcbftl27OBWaR/06XpLb/tybYX5MmbgDXz60rlb3LsAY4HvtIwr+3s\n",
       "dW0kWrlRr5LyX4jjSL90q9qelxfNA1YtKdai/AD4Munigh51yL4W8JikMyT9WdJP89Vylc9u+wng\n",
       "OOBBUuPwpO3J1CB7QbOsq/Pqy+Hr8O/3k8Cl+XXl80vaA5hj+46GRW1nr2sjUctqu6RlgHOBg20/\n",
       "U1zmdAVB5T6XpF2Bv9ueTpNhUqqanXRl3GbAj2xvBvyLhu6ZqmaXtDZwCOlGqNWBZSR9rLhOVbP3\n",
       "poWslf0ckv4LeMn2WX2sVpn8+RaCrwFHFmf3sUmf2evaSLRyo16lSFqc1ED8wvYFefY8Savl5W8E\n",
       "/l5Wvj78P2B3SQ8AZwPbS/oF9cg+h/TX1C15+nekRuPRGmR/O/BH2/+wPR84D3gn9cjeo9nvSOO/\n",
       "3zXzvMqRtB+pq/WjhdlVz7826Y+L2/O/2zWBWyWtSj+y17WR+PeNepKWIBViLio5U1NKN3z8DLjb\n",
       "9gmFRRcBPXdCfgK4oHHbstn+mu3RttciFU7/YPvj1CP7o8BDktbLs3YE/gJcTMWzkwrsW0laKv/+\n",
       "7Ei6cKAO2Xs0+x25CPiIpCUkrUUaw61yjwOQNIHUzbqH7RcKiyqd3/adtle1vVb+dzuHdAHEPPqT\n",
       "3XYtf4CdgXtIhZcjys6ziKzvJvXn3wZMzz8TgJWAKaQrJ64EVig76yI+x7bARfl1LbKThnm5Bbid\n",
       "9Nf48jXK/hVSo3YnqfC7eFWzk84y5wIvkeqF+/eVldQdMovUGL63gvk/CdxHujKo59/sj6qYv5D9\n",
       "xZ5j37D8fmCl/maPm+lCCCE0VdfuphBCCEMgGokQQghNRSMRQgihqWgkQgghNBWNRAghhKaikQgh\n",
       "hNBUNBIh9EHSK3mI9J6fxgHTBrLvMb0N7xxClXTy8aUhDAfP2R5XdogQyhJnEiH0g6TZko6VdIek\n",
       "m/KAfD1nB3/ID6qZksf0R9Kqks6XdFv+2SrvaoSk05QeRnWFpNeV9qFC6EU0EiH0bamG7qYP5fkm\n",
       "Dd+9CekBWD1jcv0QOMPpQTW/Ak7K808CrrY9ljTI4N15/rrAybY3Ap4EPtD5jxRC62JYjhD6IOkZ\n",
       "28v2Mv8BYDvbs/MIv4/YXlnSY8Bqtl/J8+faXkXS34E1nB6S1bOPMcCVTk9uI9c7Frd9zBB8tBBa\n",
       "EmcSIQyO4l9bzcbu723+i4XXrxB1wlAx0UiE0H97F/77x/z6j6Qh1SE9g+Da/Poq4LOQntEuabmh\n",
       "ChnCQMRfLSH0bSlJ0wvTl9n+Wn69oqTbgReAffK8g4AzJH2Z9JCd/fP8g4HTJH2KdMbwGdIjPRv7\n",
       "e6P/N1RK1CRC6Idck9jc6VnUIQxb0d0UQv/EX1ehK8SZRAghhKbiTCKEEEJT0UiEEEJoKhqJEEII\n",
       "TUUjEUIIoaloJEIIITQVjUQIIYSm/j9sT2epbnCwSgAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32c3a8ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.__version__\n",
    "%matplotlib inline\n",
    "\n",
    "print len(model2L_noNoise_with212.train_history_)\n",
    "histo = pd.DataFrame(model2L_noNoise_with212.train_history_)\n",
    "\n",
    "print histo\n",
    "print histo['LER'].describe()\n",
    "\n",
    "my_plot = histo['LER'].plot(title=\"Error rate Trend\",legend=None)\n",
    "my_plot.set_xlabel(\"Epoch\")\n",
    "my_plot.set_ylabel(\"LER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f32c3a48690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYXmV97vHvDUnkaA4cAiRoIiVSrBqloFXRSAHBXQG7\n",
       "0eKBBk97d1sVbGtJdFuwXqYxVovW7d6XVkikgkVFGqxgwrEoNlBNIiVgghIkQiaEEAQ5Jea3/3ie\n",
       "l7wzmUlmMvO+az2z7s91vdes07vmnklmfrOe3zooIjAzM2vZo+oAZmZWLy4MZmbWiwuDmZn14sJg\n",
       "Zma9uDCYmVkvLgxmZtaLC4NZwSRdKOnSqnPY6OLCYDYIkm6S9J4B1h0v6bH8elzStrb5X0ua2sFo\n",
       "vhDJRtyYqgOYFWLAX8ARcQuwP4Ck5wP3AuMjYlvfbSXtGRG/7VhKsxHgIwYblSQdLulKSRskbZT0\n",
       "j3n5HpL+t6S1knokLZL03LxuL0n/nLd/RNJtkg6W9CngeOCL+SjgCzv71H1yXCjpW5IulfQoMFvS\n",
       "eElflfSApHWSPilpj7z9OZJ+IOkzkjZJ+oWkU9r2N13SzflIZAlw4Ah/68xcGGz0kbQn8F3SX+7P\n",
       "B6YAl+fV5wCzgVnAC4D9gC/mdbOB5wJTgUnA/wSejIiPAbcAfx4R+0fEh4YY6TTgmxExHrgMWAg8\n",
       "AxwBvAw4GXhv2/bHAXcDBwALgK+2rbsMuD2v+2TO7OEkG1EuDDYaHQccCnwkIp6MiKcj4ta87h3A\n",
       "ZyNibUT8BpgLnJWLyTOkX7hHRrI8Ih5r22+vo4EhuDUiFufp8cCpwIdztoeAi4Cz2ra/LyK+GulG\n",
       "Zl8DDs1HLs8Dfh/4eERsyUNYVw8jl1m/3GOw0ehw0i/XHcb4SQXjvrb5X5J+Dg4GLs3v/YakCcA/\n",
       "Ax+LiK152939y3xd2/TzgbHAg9Kzv8/3yDla1rcmIuKJvN1+OeMjEfFk27b35cxmI8ZHDDYa3Q88\n",
       "Lx8F9PUAMK1t/nnAVqAnIrZGxN9GxIuAVwF/BPxp3m53i0L0ee/9wNPAARExMb/GR8SLB7GvB4GJ\n",
       "kvZpW/b8YWQz65cLg41Gy0i/ROdL2ic3lV+V110OfFjSNEn7AfOAb0TENkmzJL04F5THgC1A6wyi\n",
       "HlJPYKh6DfNExIPAEuBzkvbPzfAjJL12VzuKiPuA/wQ+IWmspNeQipfZiHJhsFEnDyG9Cfgd0hDN\n",
       "/cBb8+qLSUNG/w78AngC+GBedwjwTeBRYBVwU94W4PPAmflMoYt2FaHPdN+/6P8UGJc/x6b8OQ/Z\n",
       "yfbt828HXpHf9zfAol1kMRsydfJBPZJeCHyjbdELgI+Txm7/hXQYvBZ4a0Rszu+ZC7yb9JfahyJi\n",
       "SccCmpnZDjpaGHp9onSe9q9IZ4x8ENgYEQsknQ9MjIg5ko4mnY53LOkUw+uAGQM0Ec3MrAO6OZR0\n",
       "InBPRNxPOq+7dQi8CDgjT58OXJ5PxVsL3EMqJGZm1iXdLAxnsf0io8kR0ZOne4DJefowep/at450\n",
       "5GBmZl3SlcIgaRypGfjNvuvyRTw7G8/yqXhmZl3UrQvcTgV+nK/yBOiRdEhErJd0KLAhL/8VvS/W\n",
       "mZqXPUuSC4WZ2W6IiMFdJR8RHX+Rzkya3Ta/ADg/T88B5ufpo4EVpFP5pgM/JzfI294b3cjcoe/D\n",
       "hVVnaGL20vM7u7OPRPah/O7s+BGDpH1Jjef3tS2eD1yR72+/lnyOeUSsknQF6fzurcD7I39Fo8S0\n",
       "qgMMw7SqAwzTtKoDDMO0qgMMw7SqAwzDtKoDDMO04by544Uh0o3KDuyzbBOpWPS3/TzS1ahmZlYB\n",
       "X/ncXQurDjAMC6sOMEwLqw4wDAurDjAMC6sOMAwLqw4wDAuH8+auXeA2UiRFDLaBYmZmwNB+d/qI\n",
       "oYskzao6w+4qOTuUnd/Zq9Hk7C4MZmbWi4eSzMwawENJZma221wYuqjJY5ZVKzm/s1ejydldGMzM\n",
       "rBf3GMzMGsA9BjMz221FFgapa3eFHVFNHrOsWsn5nb0aTc5eZGEA9qo6gJnZaFVkjwHiwAgerjqL\n",
       "mVkpmtBj8BGDmVmHuDB0UZPHLKtWcn5nr0aTs5daGJ5TdQAzs9Gq1B7DMRH8pOosZmalcI/BzMx2\n",
       "W6mFocihpCaPWVat5PzOXo0mZy+1MPiIwcysQ0rtMbw5gquqzmJmVgr3GMzMbLe5MHRRk8csq1Zy\n",
       "fmevRpOzd7wwSJog6VuS7pK0StIrJE2StFTSaklLJE1o236upDWS7pZ08gC7LbL5bGZWgo73GCQt\n",
       "Am6OiIsljQH2BT4GbIyIBZLOByZGxBxJRwOXAccCU4DrgBkRsa1tfwFxXgSf72hwM7NRpDY9Bknj\n",
       "geMj4mKAiNgaEY8CpwGL8maLgDPy9OnA5RGxJSLWAvcAx/Wzax8xmJl1SKeHkqYDD0m6RNJPJH1F\n",
       "0r7A5Ijoydv0AJPz9GHAurb3ryMdOfTlHkOXlZwdys7v7NVocvZOP/BmDPBy4AMRcbuki4A57RtE\n",
       "RKThoQH1s+74M6UftIraZmBFRNwE278hnh/Z+Za65GlY/plAnfIMeh6YKak2eZoy3zZ9Tp5dyxB0\n",
       "tMcg6RDgRxExPc+/BpgLvAB4fUSsl3QocGNEHCVpDkBEzM/bXwtcEBHL2vYZEJ+L4C87FtzMbJSp\n",
       "TY8hItYD90uakRedCNwJXA3Mzstmw7MXqy0GzpI0TtJ04Ejgtn52XeRQkplZCbpxHcMHga9LWgm8\n",
       "BPgUMB84SdJq4IQ8T0SsAq4AVgHXAO+P/g9pimw+N3nMsmol53f2ajQ5e6d7DETEStLpp32dOMD2\n",
       "84B5u9itjxjMzDqk1HslfTuCM6vOYmZWitr0GDqoyKEkM7MSlFoYihxKavKYZdVKzu/s1Why9lIL\n",
       "g48YzMw6pNQew+0R/d4qw8zM+tGEHkORQ0lmZiUotTAUOZTU5DHLqpWc39mr0eTspRYGHzGYmXVI\n",
       "qT2GDRHP3pHVzMx2oQk9hiKHkszMSlBqYShyKKnJY5ZVKzm/s1ejydlLLQzjJAZ1SGRmZkNTao9h\n",
       "C7B/BE9XncfMrARN6DE8RaHDSWZmdVdyYSiuAd3kMcuqlZzf2avR5OylFoan8RGDmVlHlNpjuAd4\n",
       "YwRrqs5jZlaCJvQYfMRgZtYhpRaGIpvPTR6zrFrJ+Z29Gk3OXnJhKK75bGZWglJ7DDcAfxfBdVXn\n",
       "MTMrQRN6DD5iMDPrkFILQ5HN5yaPWVat5PzOXo0mZ+94YZC0VtJPJS2XdFteNknSUkmrJS2RNKFt\n",
       "+7mS1ki6W9LJA+y2yOazmVkJOt5jkHQvcExEbGpbtgDYGBELJJ0PTIyIOZKOBi4DjgWmANcBMyJi\n",
       "W9t7A+IS4AcRXNzR8GZmo0Qdewx9w5wGLMrTi4Az8vTpwOURsSUi1gL3AMf1s78ih5LMzErQjcIQ\n",
       "wHWS/lPS+/KyyRHRk6d74NmnsR0GrGt77zrSkUNfRTafmzxmWbWS8zt7NZqcfcwI5diZV0fEg5IO\n",
       "ApZKurt9ZUREGh4aUD/rXnsiHNgjfWc8sBlYERE3wfZviOdHdr6lLnkaln8mUKc8g54HZkqqTZ6m\n",
       "zLdNn5Nn1zIEXb2OQdIFwOPA+4BZEbFe0qHAjRFxlKQ5ABExP29/LXBBRCxr20dAfCJl54KuhTcz\n",
       "K1htegyS9pG0f57eFzgZuANYDMzOm80GrsrTi4GzJI2TNB04Eritn10XOZRkZlaCTvcYJgO3SFoB\n",
       "LAO+GxFLgPnASZJWAyfkeSJiFXAFsAq4Bnh/9H9IU2TzucljllUrOb+zV6PJ2TvaY4iIe0njo32X\n",
       "bwJOHOA984B5u9i1r2MwM+uQUu+V9B7g+AjeVXUeM7MS1KbH0EE+YjAz65CSC0Nxzecmj1lWreT8\n",
       "zl6NJmcvtTAU2Xw2MytBqT2GE4GPRXBC1XnMzErQhB7D0xQ4lGRmVoJSC0ORzecmj1lWreT8zl6N\n",
       "JmcvuTD4iMHMrANK7THMAK6J4HeqzmNmVoIm9BiKHEoyMytBqYWhyOZzk8csq1ZyfmevRpOzl1oY\n",
       "fMRgZtYhpfYYngM8HsG4qvOYmZWgCT2GLYCk8oaTzMzqrsjCEEGQHuk5vuosQ9HkMcuqlZzf2avR\n",
       "5OxFFoZsMzCh6hBmZqNNkT2GiJDE7cCfR/T76E8zM2vThB4DwCPAxKpDmJmNNiUXhuKGkpo8Zlm1\n",
       "kvM7ezWanN2FwczMeim5x7AAeDiCT1edycys7prSY/ARg5lZB5RcGIprPjd5zLJqJed39mo0OXvH\n",
       "C4OkPSUtl3R1np8kaamk1ZKWSJrQtu1cSWsk3S3p5F3s2kcMZmYd0PEeg6S/AI4B9o+I0yQtADZG\n",
       "xAJJ5wMTI2KOpKOBy4BjgSnAdcCMiNjWZ3+tHsOpwLkRnNLRL8DMbBSoTY9B0lTgjcA/Aa1ApwGL\n",
       "8vQi4Iw8fTpweURsiYi1wD3AcTvZvY8YzMw6oNNDSf8AfARo/6t/ckT05OkeYHKePgxY17bdOtKR\n",
       "w0AeobDC0OQxy6qVnN/Zq9Hk7GNGKMcOJP0RsCEilg8UMo8J7Wwsq991khbCQRvhvVOlvzsPWBER\n",
       "N+V1s/K+PT+C8y11ydOw/DOBOuUZ9DwwU1Jt8jRlvm36nDy7liHoWI9B0jzgbGAr6aE6zwWuJPUQ\n",
       "ZkXEekmHAjdGxFGS5gBExPz8/muBCyJiWZ/9tnoMewGPAnvlu62amdkAatFjiIiPRsThETEdOAu4\n",
       "ISLOBhYDs/Nms4Gr8vRi4CxJ4yRNB46EgW+QF8FTpCMKP8nNzGwEdfM6htZf9fOBkyStBk7I80TE\n",
       "KuAKYBVwDfD+2PXhTFEN6CaPWVat5PzOXo0mZ+9Yj6FdRNwM3JynNwEnDrDdPGDeEHbdakA/ONyM\n",
       "ZmaWFHuvpDTNj4C/iOBHFccyM6u1WvQYumQzhd0Ww8ys7kZDYXCPoQtKzg5l53f2ajQ5+y4Lg6S3\n",
       "DGZZRYoqDGZmJdhlj0HS8oh42a6WdUufHsM84PGIITWszcwaZyg9hgHPSpJ0Kuk+R1MkfYHt9zra\n",
       "H9gy7JQjYzNwYNUhzMxGk50NJT0A/Bh4Kn9svRYDb+h8tEEpqvnc5DHLqpWc39mr0eTsAx4xRMRK\n",
       "YKWkr0fElvzJJgFTI+KR4XzSEeQeg5nZCBtMj+Em0q2yx5COGB4CfhgRH+54uv7ztPcYTgY+EsFJ\n",
       "VWQxMyvFSF/HMCEifg38MfC1iDiOAa5crkBxt942M6u7wRSGPfNdUN8K/FteVpfLpYsaSmrymGXV\n",
       "Ss7v7NVocvbBFIa/Bb4P/DwibpN0BLBmOJ90BBXVfDYzK0Hp90oaBzwBjPUzGczMBjaiPQZJh0v6\n",
       "jqSH8uvbSs9yrlwEzwBPA/tWncXMbLQYzFDSJaRrFw7Lr6vzsroopgHd5DHLqpWc39mr0eTsgykM\n",
       "B0XEJRGxJb8WAgcP55OOsKIa0GZmdTeYwvCwpLMl7SlpjKR3Ahs7HWwIimlAtz0gvTglZ4ey8zt7\n",
       "NZqcfTCF4V2kU1XXk56U9pa8rC58xGBmNoIGe7rqn0bEQRFxEKkoXNjRVENzP3BU1SEGo8ljllUr\n",
       "Ob+zV6PJ2QdTGF7afm+k/Mzmlw/nk46wK4B3VB3CzGy0GMy9klYCr88FoXUjvZsj4sVdyNdfnl7n\n",
       "4krsAawF3hTByioymZnV3Yg8j6HNZ4EfSbqC9EyGtwCfGka+ERXBNolLgbPBhcHMbLh2OZQUEV8j\n",
       "3UBvA6kB/ea8rE4uBd4hDarQVabJY5ZVKzm/s1ejydkH02MgIu6MiH+MiC9GxKpBBttL0jJJKySt\n",
       "kvR3efkkSUslrZa0RNKEtvfMlbRG0t2STh7sFxHB3cAvqc9dX83MitXReyVJ2icinpA0BvgB8Fek\n",
       "ZztsjIgFks4HJkbEHElHA5cBxwJTgOuAGRGxrc8++x0nk/gA8IoIzu7YF2RmVqiRfh7DbouIJ/Lk\n",
       "OGBP0u0rTgMW5eWLgDPy9OnA5fnq6rXAPcBxQ/h0PwRmDjezmVnTdbQwSNpD0gqgB7gxIu4EJkdE\n",
       "T96kB5icpw8D1rW9fR3pyGGw1gC/k89SqqUmj1lWreT8zl6NJmfvaLM2DwPNlDQe+L6k1/dZH5J2\n",
       "NpbV7zpJC0mnqEK68nlFRNwk8Qj84ZnSDRtal4S3vkGeH958S13yNCz/TKBOeQY9T/r5r02epsy3\n",
       "TZ+TZ9cyBF17HoOkjwNPAu8FZkXEeqUnw90YEUdJmgMQEfPz9tcCF0TEsj77GXCcTOIm4JMRXN/B\n",
       "L8XMrDi16DFIOrB1xpGkvYGTgOWkW3jPzpvNBq7K04uBsySNkzQdOBK4bYifdg0wY7jZzcyarJPj\n",
       "8YcCN+QewzLg6oi4HpgPnCRpNXBCniefBnsFsAq4Bnh/DP1wZg2poNRSk8csq1ZyfmevRpOzd6zH\n",
       "EBF30M89lfKtNfq93iAi5gHzhvFpVwPHD+P9ZmaNV/Qzn3dcx4uAKyN4YZdjmZnV2lB6DKOtMOxF\n",
       "Oktpvwi2djeZmVl91aL5XIUIniLdz2laxVH61eQxy6qVnN/Zq9Hk7KOqMGS1bkCbmdXdqBpKSuv5\n",
       "P8DPIvhCF2OZmdVaY4eSMl/LYGY2DKO1MNRyKKnJY5ZVKzm/s1ejydlHY2FYTU0Lg5lZCUZjj2Es\n",
       "8BgwMYInu5fMzKy+Gt1jiGALcCPw9qqzmJmVaNQVhuzvgb+s27MZmjxmWbWS8zt7NZqcvVa/OEfQ\n",
       "DcBTwBurDmJmVppR12PYvh1vB/5HBLM6n8rMrN4a3WNo801gusSxVQcxMyvJqC0MuQn9FeAdVWdp\n",
       "afKYZdVKzu/s1Why9lFbGLLvAadUHcLMrCSjtseQtmUP4AHgDyK4t7PJzMzqyz2GLIJtwLXAqVVn\n",
       "MTMrxaguDFltCkOTxyyrVnJ+Z69Gk7M3oTAsAV6Xn+5mZma7MKp7DNvfw63ABREs7VAsM7Nac49h\n",
       "R9dQk+EkM7O6a0phuAp4u8TzqgzR5DHLqpWc39mr0eTsHS0Mkg6XdKOkOyX9l6QP5eWTJC2VtFrS\n",
       "EkkT2t4zV9IaSXdLOnkkckRwB/AZ4F8l9h2JfZqZjVYd7TFIOgQ4JCJWSNoP+DFwBvAuYGNELJB0\n",
       "PjAxIuZIOhq4DDgWmAJcB8yIiG1t+xxyjyG9DwGXAPsCf5JPZTUza4Ta9BgiYn1ErMjTjwN3kX7h\n",
       "nwYsypstIhULgNOByyNiS0SsBe4BjhuZLATwZ8ABwGKJiSOxXzOz0aZrPQZJ04CXAcuAyRHRk1f1\n",
       "AJPz9GHAura3rSMVkhERwVPAG4CfA7dLvGSk9j0YTR6zrFrJ+Z29Gk3OPmaEcuxUHkb6NnBuRDwm\n",
       "bT+aiYiQtLPxrB3WSVoIrM2zm4EVEXFTXjcr77ffedCrge9A3AZcL33y/8HfXD/Y9zd1vqUueRqW\n",
       "fyZQpzyDngdmSqpNnqbMt02fk2fXMgQdv45B0ljgu8A1EXFRXnY3MCsi1ks6FLgxIo6SNAcgIubn\n",
       "7a4FLoiIZW37260eQ//ZeClwJfBvwNwIfjMS+zUzq5va9BiUDg2+CqxqFYVsMTA7T88mnU7aWn6W\n",
       "pHGSpgNHArd1Kl8EK4HfByYBd0q8qVOfy8ysFJ3uMbwaeCfweknL8+sUYD5wkqTVwAl5nohYBVwB\n",
       "rCJdlPb+6PAhTQSPRPBO4D3AFyTO7tTnavKYZdVKzu/s1Why9o72GCLiBwxcfE4c4D3zgHkdCzWA\n",
       "CK6XeDOwROL6CB7odgYzszpoxL2ShrZ/PgEcA7wpn+JqZla82vQYCvUpYCrwvqqDmJlVwYWhjwie\n",
       "Ad4GXCDx3p1tO9TrIJo8Zlm1kvM7ezWanN2FoR8R3AXMAj4ucW5/20j8AbBSYlYXo5mZdZx7DDv9\n",
       "XDwPuAX4qwi+2Wfd9wCRbrHxCvcjzKzO3GMYIRH8knQfpy9JzGwtlzgW+D3gzaTv4Vva1o2VeJ3E\n",
       "eRL7dDuzmdlwuTDsQgTLgQ8AV0m8PN+l9ePA/HzvpfOBeRInSSwENgCfBf4Y+HLeHmj2mGXVSs7v\n",
       "7NVocvau3CupdBH8S74b65XAb4DxwFvzuuslVpGe97CIdGuNB/PRwg+BDwGfrya5mdnQuccwpM/N\n",
       "HsBrgWciuHUQ208D/gNYAHwrD02ZmXXdUH53ujB0mMQxpKOG/wb8BHizb9ZnZt3m5nONRPDjCGYD\n",
       "h8Dl24BvSOUN4ZU83gpl53f2ajQ5uwtDl0SwFf7sM8BY4P+2N6XNzOrEQ0ldJrEfsBS4H3hPBI9V\n",
       "HMnMGsBDSTUWwePA64FHgWUSn5C4RWKtxNk+kjCzqrkwdNH2x/DxVATvIz2HYi/gk8DZwF8A10m8\n",
       "cPc/BzMkPpDPiBoxJY+3Qtn5nb0aTc7uwlChCL4WwfkRLIngFuBY4Grgh/lIYrzEnhJ7SBwgcZTE\n",
       "3gPtT+LtpGsnXgPcLrFM4h0lNrvNrDruMdSQxFTgIuCNpCMKgM3AJuAgYAnpCXc/AX5JeujR24Hf\n",
       "Bd4awUqJscAbgI8AzwcuJd336Q5gX2A/4GcRPNmlL8vMKuTrGEaR3HPYI4Lf5vmDgDeRHok6EzgC\n",
       "uBn4NvCN/prZEq8ATgOOB44Cfg08RSoYPwC+Dlze+hxmNvq4MNSUpFkRcdPI7hPt7p1dJSYAJ5Eu\n",
       "wDsIuBC4IoJtO2478tm7qeT8zl6N0ZbdZyU1yHBu9x3B5nw78dcCHwTOA34qcabEniOV0czK4iMG\n",
       "e1YetjoV+BvgBcBi4FbS0NPDwK0RPJ23fSlpKOrmCB6tJrGZDZaHkmzYJKaTnkUxk9SsnkJqbi8F\n",
       "ZgATgHuA44CVwO3A8vy6K13pbWZ14cJQU6WPWULcRTpT6l7g3yPYlm8v/irgGOBl+XU48HNgI+lI\n",
       "42HSGVUPAT2kM6zG5dddwJ2dbnyX/r139u4bbdmH8ruzo+e3S7qYdFfRDRHx4rxsEvAvpGGItcBb\n",
       "I2JzXjcXeDfwW+BDEbGkk/lsaCLoAS7ps+wJ4Lr8Ap697ccRpMeeHgBMyh+fR7pWYwLprKhtpCfh\n",
       "HSJxH7C17bWFdCSyFFgGPOyzpsy6o6NHDJKOBx4HvtZWGBYAGyNigaTzgYkRMUfS0cBlpF8cU0i/\n",
       "aGZExLY++yz2iMH6J3Eg6d98T9IfK2NI128cB5wMvIT0cKSHSU/I68mv/qY3ABtavRAzS2o1lCRp\n",
       "GnB1W2G4G3hdRPRIOgS4KSKOykcL2yLi03m7a4ELI+I/+uzPhaGB8gV7BwKT8+vgPh/bpw8iPWlv\n",
       "Z0XkV6QL/Nw4t0aozVDSACZHRE+e7iH9IAMcRnraWcs60l+Ro8ZoG7Pspgi2AA/m107lJ+1NoFfB\n",
       "uOjVcN5YUi9kMjAVeKHEr0lDmveT/s/dn1/35dfG4ZwSPBKq/t4Ph7NXY7jZK72HTkSEpJ390PW7\n",
       "TtJC0g8zpEbmitY3YfuN6jw/kvMtdckzyPlNkiaTjhC+E3HeTe3rUwH5wzPhhZPhSxuBqbDoeNh3\n",
       "Mpy5DzANbthberoHTr0LuA++tAc83AMfvybNj5sBW6LDX89MoA7fzyHPAzMl1SZPU+bbps/Js2sZ\n",
       "gqqGkmZFxHpJhwI35qGkOQARMT9vdy1wQUQs67M/DyVZ10jsTzpRovWa1md+ImlY6j7SD1/rSON+\n",
       "4IH8+nXVRx1mdR9KWgzMBj6dP17VtvwySZ8jDSEdCdxWQT6zZ+V7T/1Xfu1AYi/S2VbtxeIE0lDV\n",
       "lPySxAOkZ3A8TjqC6VtIeoBNvv7D6qDTZyVdDryO1DTsIV1R+6/AFaQfprX0Pl31o6TTVbcC50bE\n",
       "9/vZZ7FHDE0es6xalfnzUcdhwHNJd7WdzPYjj9bHg0l9kdZV5hu3f7xkb3jXit7Lnp3elPsvtVTy\n",
       "/5vRlr02RwwR8bYBVp04wPbzgHmdS2TWffmo42e72i7fn2oC6Q+pA7Z//M1xefkReVn7+okSj7FD\n",
       "Mek13XfZw3UuJlY9X/lsVrC2M7D6FJMdCkj79CTSkFZ74XgYeAx4gnRCx69IV6qPI11Tson07I8N\n",
       "pIsTn/KwV1lqdR3DSHNhMBueXEzGs2Mx2Q/Ym1Q4ppCGt54mFYJJpFudHEwqFM9he6/kIVIxebTP\n",
       "x/6WPeqLD6vhwlBTo23MsiQl569j9jzsdRipV3ggqdBMyK/x2z9eNR3OiD7rtzJwAXmcdHHiUF5P\n",
       "deKsrzp+3wer1j0GMxud8n2rWhcDDkh6c69fUPnW7nvTu4C0T+9Huptv695a+w7iNVbiEfLtUOhz\n",
       "e5R+Xj59eBd8xGBmRZMYQxrqOniQr9YwWH8FZCOwP3AIqUgF6YaOD5CujG+9Hiytx+KhJDOzAUjs\n",
       "TbqfVuv+Wu2vg0hN+PX5o0gN+ENJ16a0XgeTikjr+pTHSL2XA4CxbL+9yiYGHjZr9Vye6vCXDLgw\n",
       "1NZoG7MsScn5nb0aO8uej1IOYfv1KfuTmvQPkx4bMJXUrJ9Ir57LDkNnE0i3n28vFptJRafvkUyr\n",
       "//JE/riZdB3LDr/E3WMwM+uyPIzUGlbqz48Hs5/cc9mL3sVjIqmh3zqKmZHn2/sq+5CGz/aSWE8q\n",
       "FE/m3Y6D7+4t8Qt6F5dB8xGDmVmhJPYlDYntQ2rqt3oie9J7iGwy6K88lGRmZs8ayu/OPTodxrbr\n",
       "ewvrkpScHcrO7+zVaHJ2FwYzM+vFQ0lmZg3goSQzM9ttLgxd1OQxy6qVnN/Zq9Hk7C4MZmbWi3sM\n",
       "ZmYN4B6DmZntNheGLmrymGXVSs7v7NVocnYXBjMz68U9BjOzBnCPwczMdlvtCoOkUyTdLWmNpPOr\n",
       "zjOSmjxmWbWS8zt7NZqcvVaFQdKewBeBU4CjgbdJ+t1qU42omVUHGIaSs0PZ+Z29Go3NXqvCABwH\n",
       "3BMRayNiC/AN4PSKM42kCVUHGIaSs0PZ+Z29Go3NXrfCMIX0nNSWdXmZmZl1Sd0KQ1mnSA3dtKoD\n",
       "DMO0qgMM07SqAwzDtKoDDMO0qgMMw7SqAwzDtOG8uVanq0p6JXBhRJyS5+cC2yLi023b1CewmVlB\n",
       "iny0p6QxwM+APwQeAG4D3hYRd1UazMysQcZUHaBdRGyV9AHg+6SHWX/VRcHMrLtqdcRgZmbVq1vz\n",
       "eadKuvjY7ZplAAAFkklEQVRN0uGSbpR0p6T/kvShvHySpKWSVktaIqm2p8RJ2lPScklX5/kiskua\n",
       "IOlbku6StErSKwrKPjf/n7lD0mWSnlPX7JIultQj6Y62ZQNmzV/bmvwzfHI1qZ/N0l/2z+T/Mysl\n",
       "XSlpfNu62mTPeXbI37buLyVtkzSpbdmQ8hdTGAq8+G0L8OGIeBHwSuDPc945wNKImAFcn+fr6lxg\n",
       "FdvPFisl++eB70XE7wIvAe6mgOySpgHvA14eES8mDaeeRX2zX0L6eWzXb1ZJRwN/QvrZPQX4kqQq\n",
       "f//0l30J8KKIeCmwGpgLtcwO/edH0uHAScB9bcuGnL/qL24oirr4LSLWR8SKPP04cBfpmozTgEV5\n",
       "s0XAGdUk3DlJU4E3Av8EtM5kqH32/Ffe8RFxMaS+VUQ8SgHZgV+T/qDYJ5+IsQ/pJIxaZo+IW4BH\n",
       "+iweKOvpwOURsSUi1gL3kH6mK9Ff9ohYGhHb8uwyYGqerlV2GPB7D/A54K/7LBty/pIKQ7EXv+W/\n",
       "BF9G+s82OSJ68qoeYHJFsXblH4CPANvalpWQfTrwkKRLJP1E0lck7UsB2SNiE/BZ4JekgrA5IpZS\n",
       "QPY2A2U9jPQz21L3n993A9/L00Vkl3Q6sC4iftpn1ZDzl1QYiuySS9oP+DZwbkQ81r4uUue/dl+X\n",
       "pD8CNkTEcrYfLfRS1+ykM+1eDnwpIl4O/IY+Qy91zS7pCOA80sVJhwH7SXpn+zZ1zd6fQWSt5dch\n",
       "6WPAMxFx2U42q1V2SfsAHwUuaF+8k7fsNH9JheFXwOFt84fTuwrWjqSxpKJwaURclRf3SDokrz8U\n",
       "2FBVvp14FXCapHuBy4ETJF1KGdnXkf5quj3Pf4tUKNYXkP33gVsj4uGI2ApcCfwBZWRvGej/SN+f\n",
       "36l5Wa1IOoc0hPqOtsUlZD+C9AfFyvxzOxX4saTJ7Eb+kgrDfwJHSpomaRypmbK44kwDkiTgq8Cq\n",
       "iLiobdViYHaeng1c1fe9VYuIj0bE4RExndT8vCEizqaM7OuB+yXNyItOBO4Erqbm2UlN8ldK2jv/\n",
       "/zmR1PwvIXvLQP9HFgNnSRonaTpwJOkC1tqQdApp+PT0iHiqbVXts0fEHRExOSKm55/bdaSTGHrY\n",
       "nfwRUcwLOJV0ZfQ9wNyq8+wi62tI4/MrgOX5dQowCbiOdNbDEmBC1Vl38XW8Dlicp4vIDrwUuB1Y\n",
       "Sfqre3xB2f+aVMjuIDVvx9Y1O+lo8gHgGVL/7107y0oa6riHVADfULPs7wbWkM7maf28fqmO2fvk\n",
       "f7r1ve+z/hfApN3N7wvczMysl5KGkszMrAtcGMzMrBcXBjMz68WFwczMenFhMDOzXlwYzMysFxcG\n",
       "sz4k/Tbfbrz16ntTsuHse1p/t0o2q5NaPcHNrCaeiIiXVR3CrCo+YjAbJElrJX1a0k8lLcs3vWsd\n",
       "BdyQH/ByXb4nPpImS/qOpBX59cq8qz0lfVnpAU7fl7RXZV+UWT9cGMx2tHefoaS35OVBuhX2S0gP\n",
       "jWrdA+sfgUsiPeDl68AX8vIvADdGxEzSjfxW5eVHAl+MiN8DNgP/vfNfktng+ZYYZn1Ieiwi9u9n\n",
       "+b3A6yNibb5z7oMRcaCkh4BDIuK3efkDEXGQpA3AlEgPlmrtYxqwJNITzsj9i7ER8akufGlmg+Ij\n",
       "BrPd1/5X1UD3vu9v+dNt07/FvT6rGRcGs6H5k7aPt+bpW0m3J4d0H/9/z9PXA/8L0jPLJT23WyHN\n",
       "hsN/qZjtaG9Jy9vmr4mIj+bpiZJWAk8Bb8vLPghcIukjpAfTvCsvPxf4sqT3kI4M/oz0uMu+47ce\n",
       "z7VacY/BbJByj+GYSM9mNhu1PJRkNnj+K8oawUcMZmbWi48YzMysFxcGMzPrxYXBzMx6cWEwM7Ne\n",
       "XBjMzKwXFwYzM+vl/wP2XcebIzwE/gAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32c39a6f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_plot2 = histo['cost'].plot(title=\"cost Trend\",legend=None)\n",
    "my_plot2.set_xlabel(\"Epoch\")\n",
    "my_plot2.set_ylabel(\"cost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histo.to_pickle('./ver1-L2-313-nonoise.pa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "Total Sentence :  4120\n",
      "chun label_error_rate :  0.764031235273\n",
      "Lee's label_error_rate :  0.764031235273\n",
      "Mission Complete\n"
     ]
    }
   ],
   "source": [
    "label_error_rate = 0.\n",
    "pr_error_rate = 0.\n",
    "pr_count = 0\n",
    "print len(x_test)\n",
    "WRITE_RESULT = \"./dataCebuano/dev_predict_result_2L_noNoise_with313_epo137.txt\"\n",
    "\n",
    "with open(WRITE_RESULT, 'w+') as f:\n",
    "    for index in range( len(x_test) ) :\n",
    "        prepre = model2L_noNoise_with212.predict( x_test[index])\n",
    "        ## print actual\n",
    "        y_actual = decode_all_actual( y_test[index], y_test_mask[index], batch_size , True)\n",
    "        ## print pred\n",
    "        y_predict = decode_all_pred( np.argmax(prepre[0],axis=2) , x_test_mask[index],  batch_size , False)\n",
    "        for a, b in zip( y_actual, y_predict):\n",
    "            # print \"---------\"\n",
    "            # print \"Target : \", a\n",
    "            # print \"Predict: \", b\n",
    "            # print _count_grade(a,b)\n",
    "            pr_error_rate += _count_grade( a, b)\n",
    "            f.write(idCollect[pr_count])\n",
    "            f.write(' ')\n",
    "            f.write(b);\n",
    "            f.write('\\n');\n",
    "            pr_count += 1\n",
    "        \n",
    "        label_error_rate += check_all( y_test[index], y_test_mask[index],\n",
    "                         np.argmax(prepre[0],axis=2), x_test_mask[index],\n",
    "                         batch_size) \n",
    "\n",
    "    label_error_rate /= len(x_test)\n",
    "    pr_error_rate /= pr_count\n",
    "    print \"Total Sentence : \", pr_count\n",
    "    print \"chun label_error_rate : \", label_error_rate\n",
    "    print \"Lee's label_error_rate : \", pr_error_rate\n",
    "\n",
    "print \"Mission Complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Process once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "[ Doing : ]\n",
    "    - Read character from *.txt to build the corpus \n",
    "\n",
    "[ Result : ]\n",
    "\n",
    "-- Without Develope Data:\n",
    "\n",
    "Building corpus without develope data:\n",
    "set([' ', \"'\", '-', '?', '_', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n",
    "Total len is : 31\n",
    "Done Write to [./dataCebuano/corpus.txt]\n",
    "\n",
    "-- With Develope Data:\n",
    "\n",
    "Building corpus with develope data:\n",
    "set([' ', \"'\", ')', '(', '-', '?', '_', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n",
    "Total len is : 33\n",
    "Done Write to [./dataCebuano/corpus.txt]\n",
    "'''\n",
    "\n",
    "TRAINING_LABEL = \"./dataCebuano/train.txt\"\n",
    "DEVELOPE_LABEL = \"./dataCebuano/dev.txt\"\n",
    "WRITING_TO = \"./dataCebuano/corpus.txt\"\n",
    "\n",
    "# Special part to build corpus\n",
    "def buildCharacterCorpus(withDevelopeData = False) :\n",
    "    corpus = set( )\n",
    "    with open(TRAINING_LABEL, 'r') as ft:\n",
    "        for lines in ft:\n",
    "            for word in lines.split('\\n')[0].split(' ')[1:]:\n",
    "                if word[0] == '<':\n",
    "                    # We take every <...> as <unk> \n",
    "                    unKnownTag = '?'\n",
    "                    corpus.add( unKnownTag ) \n",
    "                else:\n",
    "                    for char in word:\n",
    "                        corpus.add(char.lower())\n",
    "    \n",
    "    if( withDevelopeData ) :\n",
    "        with open(DEVELOPE_LABEL, 'r') as fd:\n",
    "            for lines in fd:\n",
    "                for word in lines.split('\\n')[0].split(' ')[1:]:\n",
    "                    if word[0] == '<':\n",
    "                        unKnownTag = '?'\n",
    "                        corpus.add( unKnownTag ) \n",
    "                        # corpus.add(word.split('\\n')[0].lower())\n",
    "                    else:\n",
    "                        for char in word:\n",
    "                            corpus.add(char.lower())\n",
    "    \n",
    "    corpus.add(' ')\n",
    "    print \"Building corpus with\" + (\"\" if withDevelopeData else \"out\") + \" develope data:\"\n",
    "    print corpus\n",
    "    print \"Total len is : \" + str(len(corpus))\n",
    "    \n",
    "    \n",
    "    with open(WRITING_TO, 'w+') as fw:\n",
    "        for item in corpus:\n",
    "            fw.write(item + '\\n')        \n",
    "    print \"Done Write to [\" + WRITING_TO + \"]\"\n",
    "    return corpus\n",
    "\n",
    "trainingCorpus = buildCharacterCorpus()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized\n",
      "Max len is  501\n",
      "Total training data 4157\n",
      "MIssion ComplEte\n"
     ]
    }
   ],
   "source": [
    "# import theano\n",
    "# from theano import tensor as T\n",
    "# from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search as gs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import repeat\n",
    "\n",
    "#proprocessor\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def vectorized_result ( j , siz) :\n",
    "    e = np.zeros((siz, 1))\n",
    "    e[j] = 1.0\n",
    "    return np.reshape( e, siz)\n",
    "\n",
    "# TRAINING_DATA   = './dataCebuano/train.f0_ffv_fbank.fea'\n",
    "TEST_DATA = './dataCebuano/dev.f0_ffv_fbank.fea'\n",
    "# TRAIN_ARK  = './dataCebuano/train_Normalized_SELFVALID.ark'\n",
    "\n",
    "TEST_ARK  = './dataCebuano/dev_Normalized_SELFVALID_LenLessThen500.ark'\n",
    "\n",
    "\n",
    "def normalizeAndFilterData ( maxLength = 3000) :\n",
    "    # Dataset\n",
    "    x_data = []\n",
    "    x_name = []\n",
    "    record_seq = []\n",
    "\n",
    "    with open( TEST_DATA, 'r') as f:\n",
    "        for lines in f: \n",
    "            if '[' in lines :\n",
    "                id = lines.split(' ')[0]\n",
    "                x_name.append(id)\n",
    "                seq = 0\n",
    "            elif ']' in lines :\n",
    "                if seq > maxLength :\n",
    "                    x_name.pop()\n",
    "                    del x_data[-seq:]\n",
    "                else :\n",
    "                    seq += 1\n",
    "                    record_seq.append(seq)\n",
    "                    x_data.append([float(x) for x in lines.split(' ') [2:-1] ])\n",
    "            else :\n",
    "                seq += 1\n",
    "                x_data.append([float(x) for x in lines.split(' ') [2:-1] ])\n",
    "\n",
    "    print \"Normalized\"\n",
    "    x_data = preprocessing.scale( np.array(x_data) )\n",
    "\n",
    "    # x_data[separate+1]\n",
    "    # x_name\n",
    "    bitch = record_seq.index(max(record_seq))\n",
    "    print \"Max len is \", record_seq[bitch]\n",
    "    \n",
    "    print \"Total training data\", len(x_name)\n",
    "\n",
    "    # trainF = open(TRAIN_ARK, 'w+')\n",
    "    with open(TEST_ARK, 'w+') as trainF:\n",
    "        currentSeq = 0\n",
    "        for nameIndex in range( len(x_name) ):\n",
    "\n",
    "            trainF.write(str(x_name[nameIndex])+\"  [\\n\")\n",
    "\n",
    "            for valueIndex in range( (record_seq[nameIndex]) ):\n",
    "                for featureIndex in range( len(x_data[0]) ):\n",
    "                    if ( featureIndex+1) != len(x_data[0] ) :\n",
    "                        trainF.write( str(x_data[ currentSeq  + valueIndex][featureIndex]) + \" \")\n",
    "                    else:\n",
    "                        trainF.write( str(x_data[ currentSeq  + valueIndex][featureIndex]) )\n",
    "                if valueIndex+1 == (record_seq[nameIndex]):\n",
    "                    trainF.write(\" ]\\n\")\n",
    "                else:\n",
    "                    trainF.write(\"\\n\")\n",
    "            currentSeq += record_seq[nameIndex]\n",
    "\n",
    "    print \"MIssion ComplEte\"\n",
    "\n",
    "\n",
    "normalizeAndFilterData(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
